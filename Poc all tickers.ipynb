{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "\n",
    "# === Parametri ===\n",
    "poc_period = '5y'  # Periodo storico per calcolo POC\n",
    "soglia_poc = 5     # distanza massima % dal POC\n",
    "filter_start_date = pd.to_datetime(\"2000-01-01\") # Date to filter data before\n",
    "\n",
    "# === Funzione per scaricare tickers Nasdaq-100 ===\n",
    "def get_nasdaq100_tickers():\n",
    "    tickers = []\n",
    "    try:\n",
    "        url = \"https://en.wikipedia.org/wiki/Nasdaq-100\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) > 1:\n",
    "                symbol = cells[0].text.strip().replace(\".\", \"-\")\n",
    "                tickers.append(symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Errore caricamento Nasdaq100:\", e)\n",
    "    return tickers\n",
    "\n",
    "# === Funzione per scaricare tickers S&P 500 ===\n",
    "def get_sp500_tickers():\n",
    "    tickers = []\n",
    "    try:\n",
    "        url = \"https://en.wikipedia.org/wiki/List_of_S%26P%20500_companies\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) > 1:\n",
    "                symbol = cells[0].text.strip().replace(\".\", \"-\")\n",
    "                tickers.append(symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Errore caricamento S&P 500:\", e)\n",
    "    return tickers\n",
    "\n",
    "# === Funzione per scaricare tickers DAX ===\n",
    "def get_dax_tickers():\n",
    "    tickers = []\n",
    "    # Manual mapping for problematic multi-word DAX tickers to their Yahoo Finance symbols\n",
    "    dax_ticker_map = {\n",
    "        \"Adidas\": \"ADS.DE\",\n",
    "        \"Airbus\": \"AIR.DE\",\n",
    "        \"Allianz\": \"ALV.DE\",\n",
    "        \"BASF\": \"BAS.DE\",\n",
    "        \"Bayer\": \"BAYN.DE\",\n",
    "        \"Beiersdorf\": \"BEI.DE\",\n",
    "        \"BMW\": \"BMW.DE\",\n",
    "        \"Brenntag\": \"BNR.DE\",\n",
    "        \"Commerzbank\": \"CBK.DE\",\n",
    "        \"Continental\": \"CON.DE\",\n",
    "        \"Covestro\": \"1COV.DE\",\n",
    "        \"Daimler Truck\": \"DTG.DE\",\n",
    "        \"Deutsche Bank\": \"DBK.DE\",\n",
    "        \"Deutsche Börse\": \"DB1.DE\",\n",
    "        \"Deutsche Post\": \"DHL.DE\", # Corrected from DEUTSCHE POST\n",
    "        \"Deutsche Telekom\": \"DTE.DE\",\n",
    "        \"E.ON\": \"EOAN.DE\",\n",
    "        \"Fresenius\": \"FRE.DE\",\n",
    "        \"Fresenius Medical Care\": \"FME.DE\",\n",
    "        \"Hannover Re\": \"HNR1.DE\",\n",
    "        \"Heidelberg Materials\": \"HEI.DE\",\n",
    "        \"Henkel\": \"HEN3.DE\",\n",
    "        \"Infineon Technologies\": \"IFX.DE\",\n",
    "        \"Mercedes-Benz Group\": \"MBG.DE\",\n",
    "        \"Merck\": \"MRK.DE\",\n",
    "        \"MTU Aero Engines\": \"MTX.DE\",\n",
    "        \"Munich Re\": \"MUV2.DE\",\n",
    "        \"Porsche\": \"P911.DE\", # Assuming Porsche AG\n",
    "        \"Porsche SE\": \"PAH3.DE\", # Assuming Porsche SE\n",
    "        \"Qiagen\": \"QIA.DE\",\n",
    "        \"Rheinmetall\": \"RHM.DE\",\n",
    "        \"RWE\": \"RWE.DE\",\n",
    "        \"SAP\": \"SAP.DE\",\n",
    "        \"Sartorius\": \"SRT3.DE\",\n",
    "        \"Siemens\": \"SIE.DE\",\n",
    "        \"Siemens Energy\": \"ENR.DE\",\n",
    "        \"Siemens Healthineers\": \"SHL.DE\",\n",
    "        \"Symrise\": \"SY1.DE\",\n",
    "        \"Volkswagen Group\": \"VOW3.DE\", # Assuming VOW3.DE for preferred shares\n",
    "        \"Vonovia\": \"VNA.DE\",\n",
    "        \"Zalando\": \"ZAL.DE\",\n",
    "    }\n",
    "    try:\n",
    "        url = \"https://en.wikipedia.org/wiki/DAX\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        table = soup.find(\"table\", {\"id\": \"constituents\"}) # Assuming the table ID is 'constituents' as in other examples\n",
    "        if table is None: # Fallback if table id is different\n",
    "             table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) > 1:\n",
    "                symbol_from_wiki = cells[1].text.strip() # DAX symbols are in the second column\n",
    "                # Use the mapped ticker if available, otherwise use the scraped symbol + .DE\n",
    "                symbol = dax_ticker_map.get(symbol_from_wiki, symbol_from_wiki + \".DE\")\n",
    "                tickers.append(symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Errore caricamento DAX:\", e)\n",
    "    return tickers\n",
    "\n",
    "# === FTSE MIB tickers ===\n",
    "ftse_mib_tickers_list = [\n",
    "\"A2A.MI\", \"AMP.MI\", \"AZM.MI\", \"BMED.MI\", \"BMPS.MI\", \"BAMI.MI\", \"BPSO.MI\", \"BPE.MI\", \"BC.MI\", \"BZU.MI\", \"CPR.MI\", \"DIA.MI\", \"ENEL.MI\", \"ENI.MI\", \"RACE.MI\", \"FBK.MI\", \"G.MI\", \"HER.MI\", \"IP.MI\", \"ISP.MI\", \"INW.MI\", \"IG.MI\", \"IVG.MI\", \"LDO.MI\", \"MB.MI\", \"MONC.MI\", \"NEXI.MI\", \"PIRC.MI\", \"PST.MI\", \"PRY.MI\", \"REC.MI\", \"SPM.MI\", \"SRG.MI\", \"STLAM.MI\", \"STMMI.MI\", \"TIT.MI\", \"TEN.MI\", \"TRN.MI\", \"UCG.MI\", \"UNI.MI\"\n",
    " ]\n",
    "\n",
    "# === CAC 40 tickers ===\n",
    "cac40_tickers_list = [\n",
    "        \"AC.PA\",    # Accor\n",
    "        \"AI.PA\",    # Air Liquide\n",
    "        \"AIR.PA\",   # Airbus\n",
    "        \"MT.AS\",    # ArcelorMittal (Amsterdam)\n",
    "        \"CS.PA\",    # Axa\n",
    "        \"BNP.PA\",   # BNP Paribas\n",
    "        \"EN.PA\",    # Bouygues\n",
    "        \"CAP.PA\",   # Capgemini\n",
    "        \"CA.PA\",    # Carrefour\n",
    "        \"ACA.PA\",   # Crédit Agricole\n",
    "        \"BN.PA\",    # Danone\n",
    "        \"DSY.PA\",   # Dassault Systèmes\n",
    "        \"EDEN.PA\",  # Edenred\n",
    "        \"ENGI.PA\",  # Engie\n",
    "        \"EL.PA\",    # EssilorLuxottica\n",
    "        \"ERF.PA\",  # Eurofins Scientific\n",
    "        \"RMS.PA\",   # Hermès\n",
    "        \"KER.PA\",   # Kering\n",
    "        \"OR.PA\",    # L'Oréal\n",
    "        \"LR.PA\",    # Legrand\n",
    "        \"MC.PA\",    # LVMH\n",
    "        \"ML.PA\",    # Michelin\n",
    "        \"ORA.PA\",   # Orange\n",
    "        \"RI.PA\",    # Pernod Ricard\n",
    "        \"PUB.PA\",   # Publicis\n",
    "        \"RNO.PA\",   # Renault\n",
    "        \"SAF.PA\",   # Safran\n",
    "        \"SGO.PA\",   # Saint-Gobain\n",
    "        \"SAN.PA\",   # Sanofi\n",
    "        \"SU.PA\",    # Schneider Electric\n",
    "        \"GLE.PA\",   # Société Générale\n",
    "        \"STLAP.PA\",# Stellantis\n",
    "        \"STMPA.PA\",# STMicroelectronics\n",
    "        \"TEP.PA\",   # Teleperformance\n",
    "        \"HO.PA\",    # Thales\n",
    "        \"TTE.PA\",   # TotalEnergies\n",
    "        \"URW.PA\",   # Unibail Rodamco Westfield\n",
    "        \"VIE.PA\",    # Veolia\n",
    "        \"DG.PA\",    # Vinci\n",
    "        \"VIV.PA\"    # Vivendi\n",
    "    ]\n",
    "\n",
    "# === Extra tickers ===\n",
    "extra_tickers_list = [\n",
    "        \"CL=F\", \"GC=F\", \"SI=F\", \"NG=F\", \"HG=F\", \"PA=F\", \"PL=F\", \"KC=F\", \"CC=F\",\n",
    "        \"XLC\", \"XLY\", \"XLP\", \"XLE\", \"XLF\", \"XLV\", \"XLI\", \"XLB\", \"XLRE\", \"XLK\", \"XLU\",\n",
    "        \"000300.SS\", \"^HSI\", \"^N225\", \"^GDAXI\", \"FTSEMIB.MI\", \"^IXIC\", \"^GSPC\", \"^DJI\", \"^RUT\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# === Funzione per scaricare storico ===\n",
    "def get_hist(ticker, period):\n",
    "    try:\n",
    "        df = yf.download(ticker, period=period, progress=False)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Errore storico {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# === Funzione per calcolare drawdowns ===\n",
    "def calculate_drawdowns(prices):\n",
    "    if prices.empty:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    cummax = prices.cummax()\n",
    "    drawdown = (cummax - prices) / cummax * 100\n",
    "    max_dd = drawdown.max()\n",
    "    avg_dd = drawdown.mean()\n",
    "    current_dd = drawdown.iloc[-1]\n",
    "    return max_dd, avg_dd, current_dd\n",
    "\n",
    "# === Funzione per calcolare POC (Point of Control) con Volume Profile (distribuendo volume) ===\n",
    "def get_poc_daily(ticker, period=\"5y\", bins=200):\n",
    "    \"\"\"\n",
    "    Calcola il POC (Point of Control) distribuendo il volume tra High-Low di ciascuna candela.\n",
    "    \"\"\"\n",
    "    # Scarica dati\n",
    "    try:\n",
    "        df = yf.download(ticker, period=period, interval=\"1d\", progress=False, auto_adjust=False) # Use auto_adjust=False to keep High/Low/Open/Close separate\n",
    "        if df.empty:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Errore download POC data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Gestione MultiIndex colonne\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\"_\".join(map(str, col)).strip() for col in df.columns]\n",
    "\n",
    "    # Trova colonne High, Low, Volume\n",
    "    high_col = next((c for c in df.columns if 'high' in c.lower()), None)\n",
    "    low_col = next((c for c in df.columns if 'low' in c.lower()), None)\n",
    "    vol_col = next((c for c in df.columns if 'volume' in c.lower()), None)\n",
    "\n",
    "\n",
    "    if high_col is None or low_col is None or vol_col is None:\n",
    "        # print(f\"Colonne High, Low, o Volume non trovate per {ticker}. Colonne disponibili: {df.columns.tolist()}\") # Keep original print for debugging if needed\n",
    "        return None\n",
    "\n",
    "    # Calcolo bins per Volume Profile\n",
    "    price_min = df[low_col].min()\n",
    "    price_max = df[high_col].max()\n",
    "    if price_min == price_max:\n",
    "        return None\n",
    "\n",
    "    price_bins = np.linspace(price_min, price_max, bins)\n",
    "    volume_profile = np.zeros(len(price_bins) - 1)\n",
    "\n",
    "    # Distribuzione del volume\n",
    "    for _, row in df.iterrows():\n",
    "        if row[high_col] > row[low_col] and row[vol_col] > 0:\n",
    "            # Find the bins that the current candle's price range covers\n",
    "            mask = (price_bins[:-1] >= row[low_col]) & (price_bins[:-1] <= row[high_col])\n",
    "            idx = np.where(mask)[0]\n",
    "            if len(idx) > 0:\n",
    "                # Distribute the volume equally among the bins it covers\n",
    "                vol_share = row[vol_col] / len(idx)\n",
    "                volume_profile[idx] += vol_share\n",
    "\n",
    "    if volume_profile.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    # POC (midpoint of the bin with the highest volume)\n",
    "    poc_index = np.argmax(volume_profile)\n",
    "    poc_price = (price_bins[poc_index] + price_bins[poc_index + 1]) / 2\n",
    "\n",
    "    return poc_price\n",
    "\n",
    "\n",
    "# === Esecuzione sui tickers ===\n",
    "nasdaq_tickers = get_nasdaq100_tickers()\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "dax_tickers = get_dax_tickers() # Get DAX tickers\n",
    "ftse_mib_tickers_list = ftse_mib_tickers_list # Use the provided list\n",
    "cac40_tickers_list = cac40_tickers_list # Use the provided list\n",
    "extra_tickers_list = extra_tickers_list # Use the provided list\n",
    "all_tickers = list(set(nasdaq_tickers + sp500_tickers + dax_tickers + ftse_mib_tickers_list + cac40_tickers_list + extra_tickers_list)) # Combine and remove duplicates\n",
    "print(f\"Trovati {len(all_tickers)} tickers tra Nasdaq 100, S&P 500, DAX, FTSE MIB, CAC 40 e Extra\")\n",
    "\n",
    "risultati = []\n",
    "\n",
    "for ticker in all_tickers:\n",
    "    try:\n",
    "        # Determine index membership\n",
    "        is_nasdaq = ticker in nasdaq_tickers\n",
    "        is_sp500 = ticker in sp500_tickers\n",
    "        # Check if ticker *with* .DE suffix is in the modified dax_tickers list\n",
    "        is_dax = ticker in dax_tickers\n",
    "        is_ftse_mib = ticker in ftse_mib_tickers_list\n",
    "        is_cac40 = ticker in cac40_tickers_list\n",
    "        is_extra = ticker in extra_tickers_list # Check if in extra list\n",
    "        index_membership = \"\"\n",
    "        if is_nasdaq:\n",
    "            index_membership += \"Nasdaq 100\"\n",
    "        if is_sp500:\n",
    "            if index_membership: index_membership += \", \"\n",
    "            index_membership += \"S&P 500\"\n",
    "        if is_dax:\n",
    "            if index_membership: index_membership += \", \"\n",
    "            index_membership += \"DAX\"\n",
    "        if is_ftse_mib:\n",
    "            if index_membership: index_membership += \", \"\n",
    "            index_membership += \"FTSE MIB\"\n",
    "        if is_cac40:\n",
    "            if index_membership: index_membership += \", \"\n",
    "            index_membership += \"CAC 40\"\n",
    "        if is_extra and not index_membership: # Add 'Extra' only if not already in another index\n",
    "             index_membership += \"Extra\"\n",
    "\n",
    "\n",
    "        # Storico per POC (using the specified period, e.g., '5y')\n",
    "        poc_price = get_poc_daily(ticker, period=poc_period)\n",
    "        if poc_price is None:\n",
    "            continue\n",
    "\n",
    "        # Prezzo attuale\n",
    "        df_hist = get_hist(ticker, period=\"1d\") # Get latest price\n",
    "        if df_hist.empty or \"Close\" not in df_hist.columns:\n",
    "             continue\n",
    "        current_price = float(df_hist[\"Close\"].iloc[-1])\n",
    "\n",
    "\n",
    "        # Distanza % dal POC\n",
    "        distanza_poc = (current_price - poc_price) / poc_price * 100\n",
    "\n",
    "        # Filtro distanza POC\n",
    "        if abs(distanza_poc) <= soglia_poc:\n",
    "\n",
    "            # Scarica storico completo for filtering and ATH/drawdown\n",
    "            df_all = get_hist(ticker, period=\"max\")\n",
    "            if df_all.empty or \"Close\" not in df_all.columns:\n",
    "                continue\n",
    "\n",
    "            # Apply filter to include data only from filter_start_date onwards\n",
    "            df_filtered = df_all[df_all.index >= filter_start_date].copy()\n",
    "\n",
    "            # Ensure there is data after filtering\n",
    "            if df_filtered.empty:\n",
    "                # print(f\"Skipping {ticker} as it has no data after {filter_start_date.strftime('%Y-%m-%d')}\") # Optional: for debugging\n",
    "                continue\n",
    "\n",
    "\n",
    "            close_prices = df_filtered[\"Close\"]\n",
    "            all_time_high = close_prices.max()\n",
    "            max_dd, avg_dd, current_dd = calculate_drawdowns(close_prices)\n",
    "\n",
    "            risultati.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Indice\": index_membership,  # Add index membership\n",
    "                \"POC\": poc_price,\n",
    "                \"Prezzo Attuale\": current_price,\n",
    "                \"Distanza POC %\": distanza_poc,\n",
    "                \"All Time High\": float(all_time_high), # Convert to float\n",
    "                \"Max Drawdown %\": float(max_dd),       # Convert to float\n",
    "                \"Avg Drawdown %\": float(avg_dd),       # Convert to float\n",
    "                \"Current Drawdown %\": float(current_dd)# Convert to float\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore con {ticker}: {e}\")\n",
    "        continue\n",
    "\n",
    "# === Risultati ===\n",
    "df_risultati = pd.DataFrame(risultati)\n",
    "\n",
    "if df_risultati.empty:\n",
    "    print(\"⚠ Nessun titolo ha passato i filtri sulla distanza dal POC o non ha dati storici sufficienti.\")\n",
    "else:\n",
    "    # Ordina per Current Drawdown % da più grande\n",
    "    df_risultati = df_risultati.sort_values(by=\"Current Drawdown %\", ascending=False)\n",
    "    print(f\"\\nTickers entro la soglia di distanza dal POC (with historical data from {filter_start_date.strftime('%Y-%m-%d')} onwards):\")\n",
    "    # Display all rows of the DataFrame\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df_risultati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Esecuzione sul ticker selezionato ===\n",
    "# Sostituisci 'AAPL' con il ticker che ti interessa\n",
    "ticker_da_analizzare = 'PYPL'\n",
    "\n",
    "# === Parametri (mantieni se vuoi personalizzare da qui) ===\n",
    "poc_period = '5y'  # Periodo storico per calcolo POC\n",
    "soglia_poc = 5     # distanza massima % dal POC\n",
    "filter_start_date = pd.Timestamp(\"2000-01-01\") # Data di inizio per il filtro storico in analyze_stock\n",
    "\n",
    "\n",
    "# =====================\n",
    "# FUNZIONI DI SUPPORTO (da cella TQLvO0vxSg-n)\n",
    "# =====================\n",
    "\n",
    "def get_hist(ticker, period=\"max\", adjusted=False):\n",
    "    \"\"\"\n",
    "    Scarica dati storici da Yahoo Finance.\n",
    "    Appiattisce le colonne MultiIndex se presenti.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = yf.download(\n",
    "            ticker,\n",
    "            period=period,\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            auto_adjust=adjusted\n",
    "        )\n",
    "\n",
    "        # Appiattisci MultiIndex colonne\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "        # Controllo colonne fondamentali\n",
    "        required_cols = {\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"}\n",
    "        if not required_cols.issubset(df.columns):\n",
    "            print(f\"⚠ Dati incompleti per {ticker}, colonne trovate: {df.columns.tolist()}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il download dei dati per {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_poc(df, bins=200):\n",
    "    \"\"\"\n",
    "    Calcola il Point of Control (POC) distribuendo il volume tra High-Low di ciascuna candela.\n",
    "    Il volume di ogni giorno viene distribuito uniformemente sui \"bins\" di prezzo\n",
    "    compresi tra il prezzo minimo (Low) e il prezzo massimo (High) di quella giornata.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"POC non calcolabile: dataframe vuoto\")\n",
    "        return None\n",
    "\n",
    "    price_min = df[\"Low\"].min()\n",
    "    price_max = df[\"High\"].max()\n",
    "    if price_min == price_max: # Aggiunto controllo per prezzi costanti\n",
    "        print(f\"Prezzi costanti per calcolo POC: {price_min}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    price_bins = np.linspace(price_min, price_max, bins)\n",
    "    volume_profile = np.zeros(len(price_bins) - 1)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"High\"] > row[\"Low\"] and row[\"Volume\"] > 0:\n",
    "            # Trova gli indici dei bin coperti dal range High-Low\n",
    "            # Usiamo searchsorted per maggiore efficienza con grandi dataframes\n",
    "            low_bin_idx = np.searchsorted(price_bins, row[\"Low\"], side='right') - 1\n",
    "            high_bin_idx = np.searchsorted(price_bins, row[\"High\"], side='left')\n",
    "\n",
    "            # Assicurati che gli indici siano validi e che low <= high\n",
    "            low_bin_idx = max(0, min(low_bin_idx, len(price_bins) - 2))\n",
    "            high_bin_idx = max(0, min(high_bin_idx, len(price_bins) - 1))\n",
    "\n",
    "\n",
    "            if high_bin_idx > low_bin_idx:\n",
    "                bins_covered = np.arange(low_bin_idx, high_bin_idx)\n",
    "                if len(bins_covered) > 0:\n",
    "                    vol_share = row[\"Volume\"] / len(bins_covered)\n",
    "                    volume_profile[bins_covered] += vol_share\n",
    "            elif high_bin_idx == low_bin_idx and low_bin_idx < len(price_bins) -1: # Handle case where High and Low fall in the same bin\n",
    "                 volume_profile[low_bin_idx] += row[\"Volume\"] # Add all volume to that bin\n",
    "\n",
    "\n",
    "    if volume_profile.sum() == 0:\n",
    "        print(\"POC non calcolabile: volume totale zero\")\n",
    "        return None\n",
    "\n",
    "    poc_index = np.argmax(volume_profile)\n",
    "    # Assicurati che poc_index sia un indice valido per price_bins\n",
    "    if poc_index >= len(price_bins) -1:\n",
    "        poc_index = len(price_bins) - 2 # Fallback to the last valid bin midpoint\n",
    "\n",
    "\n",
    "    poc_price = (price_bins[poc_index] + price_bins[poc_index + 1]) / 2\n",
    "    return poc_price, price_bins[:-1], volume_profile\n",
    "\n",
    "\n",
    "def calculate_drawdown(prices):\n",
    "    \"\"\"Calcola drawdown massimo e periodo relativo\"\"\"\n",
    "    if prices.empty:\n",
    "        return None, None, None, None\n",
    "\n",
    "    rolling_max = prices.cummax()\n",
    "    drawdown = (prices - rolling_max) / rolling_max\n",
    "    min_dd = drawdown.min()\n",
    "    end_date = drawdown.idxmin()\n",
    "    # Trova l'indice del massimo prima o all'end_date\n",
    "    # Usiamo idxmax() con un filtro per evitare massimi successivi\n",
    "    start_date = prices.loc[:end_date].idxmax()\n",
    "    return drawdown, min_dd, start_date, end_date\n",
    "\n",
    "def calculate_ath_distance(prices):\n",
    "    \"\"\"Calcola l'All Time High e distanza % dal prezzo corrente\"\"\"\n",
    "    if prices.empty:\n",
    "        return None, None\n",
    "    ath = prices.max()\n",
    "    current_price = prices.iloc[-1]\n",
    "    distance = (current_price - ath) / ath\n",
    "    return ath, distance\n",
    "\n",
    "# =====================\n",
    "# FUNZIONE PRINCIPALE (da cella TQLvO0vxSg-n)\n",
    "# =====================\n",
    "\n",
    "def analyze_stock(ticker, poc_period=\"5y\", filter_start_date=pd.Timestamp(\"2010-01-01\")):\n",
    "    print(f\"\\nAnalisi per {ticker}\")\n",
    "\n",
    "    # --- Dati RAW (non adjusted) per POC ---\n",
    "    df_raw = get_hist(ticker, period=poc_period, adjusted=False)\n",
    "    if df_raw.empty:\n",
    "        print(f\"⚠ Dati insufficienti per POC su {ticker}\")\n",
    "        return\n",
    "\n",
    "    # --- Dati ADJUSTED per drawdown, ATH, prezzo ---\n",
    "    df_adj = get_hist(ticker, period=\"max\", adjusted=True)\n",
    "    if df_adj.empty:\n",
    "        print(f\"⚠ Dati insufficienti per analisi prezzo su {ticker}\")\n",
    "        return\n",
    "\n",
    "    # --- Filtra dati adjusted per la data di inizio specificata ---\n",
    "    df_adj_filtered = df_adj[df_adj.index >= filter_start_date].copy()\n",
    "\n",
    "    if df_adj_filtered.empty:\n",
    "        print(f\"⚠ Nessun dato disponibile per {ticker} dopo il {filter_start_date.date()}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # --- Calcolo POC e Volume Profile ---\n",
    "    poc_result = calculate_poc(df_raw, bins=200)\n",
    "    poc_price = None\n",
    "    price_bins = None\n",
    "    volume_profile = None\n",
    "\n",
    "    if poc_result is not None:\n",
    "        poc_price, price_bins, volume_profile = poc_result\n",
    "    else:\n",
    "        print(f\"POC e Volume Profile non calcolabili per {ticker} nel periodo {poc_period}\")\n",
    "\n",
    "\n",
    "    # --- Prezzo corrente e performance (basata sui dati filtrati) ---\n",
    "    current_price = df_adj_filtered[\"Close\"].iloc[-1]\n",
    "    start_price = df_adj_filtered[\"Close\"].iloc[0]\n",
    "    perf = (current_price - start_price) / start_price\n",
    "\n",
    "    # --- Drawdown (basato sui dati filtrati) ---\n",
    "    drawdown, max_dd, start_dd, end_dd = calculate_drawdown(df_adj_filtered[\"Close\"])\n",
    "\n",
    "    # --- ATH (basato sui dati filtrati) ---\n",
    "    ath, dist_ath = calculate_ath_distance(df_adj_filtered[\"Close\"])\n",
    "\n",
    "    # --- Distanza da POC ---\n",
    "    dist_poc = None # Inizializza a None\n",
    "    if poc_price is not None: # Calcola la distanza solo se il POC è stato calcolato\n",
    "       dist_poc = (current_price - poc_price) / poc_price\n",
    "\n",
    "\n",
    "    # --- Stampa risultati ---\n",
    "    print(f\"Prezzo corrente: {current_price:.2f}\")\n",
    "    print(f\"Performance dal {filter_start_date.date()}: {perf:.2%}\")\n",
    "    # Stampa risultati drawdown solo se disponibili\n",
    "    if max_dd is not None:\n",
    "        print(f\"Max Drawdown ({filter_start_date.date()} onwards): {max_dd:.2%} (da {start_dd.date()} a {end_dd.date()})\")\n",
    "    else:\n",
    "        print(f\"Max Drawdown ({filter_start_date.date()} onwards): Non calcolabile\")\n",
    "\n",
    "    # Stampa risultati ATH solo se disponibili\n",
    "    if ath is not None and dist_ath is not None:\n",
    "        print(f\"ATH ({filter_start_date.date()} onwards): {ath:.2f} | Distanza attuale: {dist_ath:.2%}\")\n",
    "    else:\n",
    "         print(f\"ATH ({filter_start_date.date()} onwards): Non calcolabile\")\n",
    "\n",
    "    # Stampa risultati POC solo se disponibili\n",
    "    if poc_price is not None and dist_poc is not None:\n",
    "        print(f\"POC ({poc_period} period): {poc_price:.2f} | Distanza da POC: {dist_poc:.2%}\")\n",
    "    else:\n",
    "        print(f\"POC ({poc_period} period): Non calcolabile\")\n",
    "\n",
    "\n",
    "    # --- Grafico con Volume Profile ---\n",
    "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "    # Plot del prezzo\n",
    "    ax1.plot(df_adj_filtered.index, df_adj_filtered[\"Close\"], label=\"Prezzo (Adj Close)\", color=\"blue\")\n",
    "    ax1.set_ylabel(\"Prezzo\")\n",
    "\n",
    "    # Linee POC e ATH\n",
    "    if poc_price is not None:\n",
    "        ax1.axhline(poc_price, color=\"red\", linestyle=\"--\", label=f\"POC {poc_price:.2f} ({poc_period})\")\n",
    "    if ath is not None:\n",
    "        ax1.axhline(ath, color=\"green\", linestyle=\"--\", label=f\"ATH {ath:.2f} ({filter_start_date.date()} onwards)\")\n",
    "\n",
    "    # Crea un secondo asse Y per il Volume Profile\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Plot del Volume Profile (come istogramma orizzontale)\n",
    "    if price_bins is not None and volume_profile is not None:\n",
    "        # Normalizza il volume profile per adattarlo al grafico del prezzo\n",
    "        # Scaliamo il volume profile in modo che si estenda per una frazione della larghezza del grafico\n",
    "        volume_scale = 0.2 # Puoi aggiustare questo valore\n",
    "        normalized_volume = volume_profile / volume_profile.max() * (df_adj_filtered.index[-1] - df_adj_filtered.index[0]) * volume_scale\n",
    "\n",
    "        # Per l'istogramma orizzontale, usiamo `barh`\n",
    "        # L'asse x sarà il volume normalizzato, l'asse y saranno i centri dei bin di prezzo\n",
    "        bin_centers = (price_bins + np.diff(price_bins)[0] / 2)\n",
    "        # Filtra i bin_centers per la lunghezza del volume_profile\n",
    "        bin_centers = bin_centers[:len(volume_profile)]\n",
    "\n",
    "\n",
    "        ax2.barh(bin_centers, normalized_volume, height=np.diff(price_bins)[0], color='gray', alpha=0.5, label=\"Volume Profile\")\n",
    "        ax2.set_xlabel(\"Volume Profile (scala arbitraria)\")\n",
    "\n",
    "\n",
    "    ax1.set_title(f\"{ticker} - Prezzo, POC, ATH e Volume Profile\")\n",
    "    ax1.legend(loc='upper left') # Sposta la legenda per evitare sovrapposizioni\n",
    "    if volume_profile is not None:\n",
    "        ax2.legend(loc='upper right') # Legenda per il volume profile\n",
    "\n",
    "    # Imposta i limiti dell'asse x per il prezzo per far spazio al volume profile\n",
    "    # Potresti voler aggiustare questo in base a quanto spazio vuoi dedicare al volume profile\n",
    "    # ax1.set_xlim(df_adj_filtered.index[0] - (df_adj_filtered.index[-1] - df_adj_filtered.index[0]) * volume_scale, df_adj_filtered.index[-1])\n",
    "    # ax2.set_xlim(0, normalized_volume.max()) # Imposta i limiti per l'asse del volume profile\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =====================\n",
    "# ESECUZIONE\n",
    "# =====================\n",
    "analyze_stock(ticker_da_analizzare, poc_period=poc_period, filter_start_date=filter_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os # Import the os module\n",
    "\n",
    "# === Salva in Excel ===\n",
    "# Ottieni il numero della settimana corrente\n",
    "week_num = datetime.now().isocalendar()[1]\n",
    "file_name = f\"Analisi POC Settimana {week_num}.xlsx\"\n",
    "file_path = os.path.join(os.getcwd(), file_name) # Get the full path\n",
    "\n",
    "# Assicurati che df_risultati esista dalla cella precedente\n",
    "if 'df_risultati' in locals() and not df_risultati.empty:\n",
    "    try:\n",
    "        df_risultati.to_excel(file_path, index=False)\n",
    "        print(f\"\\nTabella risultati salvata in '{file_path}'\") # Print the full path\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel salvataggio del file Excel: {e}\")\n",
    "else:\n",
    "    print(\"⚠ Il DataFrame 'df_risultati' non è disponibile o è vuoto. Esegui la cella precedente per generare i risultati.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
