{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# üì¶ Scarica e analizza holdings SPDR dai file ufficiali ZIP\n",
    "# ======================================================\n",
    "\n",
    "!pip install yfinance openpyxl pandas requests matplotlib --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# === CONFIG ===\n",
    "ZIP_URL = \"https://www.ssga.com/us/en/individual/library-content/products/fund-data/etfs/us/us_spdrallholdings.zip\"\n",
    "ETF_TARGETS = {\"XLC\",\"XLY\",\"XLP\",\"XLE\",\"XLF\",\"XLV\",\"XLI\",\"XLB\",\"XLRE\",\"XLK\",\"XLU\"}  # ETF settoriali SPDR\n",
    "\n",
    "print(\"üì• Scaricamento ZIP ufficiale SPDR holdings...\")\n",
    "r = requests.get(ZIP_URL)\n",
    "r.raise_for_status()\n",
    "\n",
    "zip_bytes = io.BytesIO(r.content)\n",
    "holdings_list = []\n",
    "\n",
    "with zipfile.ZipFile(zip_bytes, \"r\") as z:\n",
    "    files = [f for f in z.namelist() if f.lower().endswith(\".xlsx\")]\n",
    "    print(f\"üìÇ Trovati {len(files)} file Excel nel pacchetto.\")\n",
    "\n",
    "    regex_pattern = r'holdings-daily-us-en-(xl[a-z]{1,4})\\.xlsx'\n",
    "\n",
    "    for fname in files:\n",
    "        etf_match = re.search(regex_pattern, fname, re.IGNORECASE)\n",
    "        if etf_match:\n",
    "            etf = etf_match.group(1).upper()\n",
    "            if etf not in ETF_TARGETS:\n",
    "                print(f\"   ‚ÑπÔ∏è Skipping {fname} as ETF {etf} is not in targets.\")\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        print(f\"   üîç Elaboro {etf} ({fname}) ...\")\n",
    "        with z.open(fname) as f:\n",
    "            raw = pd.read_excel(f, header=None, engine=\"openpyxl\")\n",
    "\n",
    "            header_row = None\n",
    "            for i, row in raw.iterrows():\n",
    "                if row.astype(str).str.contains(\"Identifier\", case=False, na=False).any():\n",
    "                    header_row = i\n",
    "                    break\n",
    "            if header_row is None:\n",
    "                print(f\"      ‚ö† Nessuna intestazione trovata per {etf}, salto.\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_excel(z.open(fname), header=header_row, engine=\"openpyxl\")\n",
    "            cols = [c.strip() if isinstance(c, str) else c for c in df.columns]\n",
    "            df.columns = cols\n",
    "\n",
    "            ticker_col = None\n",
    "            for c in cols:\n",
    "                if re.search(r\"(identifier|ticker|symbol)\", str(c), re.I):\n",
    "                    ticker_col = c\n",
    "                    break\n",
    "            if ticker_col is None:\n",
    "                print(f\"      ‚ö† Nessuna colonna Ticker trovata in {etf}, salto.\")\n",
    "                continue\n",
    "\n",
    "            keep = [ticker_col]\n",
    "            for c in [\"Name\", \"Weight\", \"Weight (%)\", \"Holding\", \"Security Name\"]:\n",
    "                if c in cols:\n",
    "                    keep.append(c)\n",
    "            df = df[keep].copy()\n",
    "            df = df[df[ticker_col].astype(str).str.match(r\"^[A-Z0-9\\.\\-]{1,10}$\", na=False)]\n",
    "            df.insert(0, \"ETF\", etf)\n",
    "\n",
    "            holdings_list.append(df)\n",
    "\n",
    "if not holdings_list:\n",
    "    raise RuntimeError(\"‚ùå Nessun ETF valido trovato.\")\n",
    "\n",
    "all_holdings = pd.concat(holdings_list, ignore_index=True)\n",
    "\n",
    "# === Pulizia ticker (Yahoo accetta \"BRK-B\", non \"BRK.B\")\n",
    "all_holdings[\"Ticker\"] = (\n",
    "    all_holdings.iloc[:,1]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\".\", \"-\", regex=False)\n",
    ")\n",
    "\n",
    "# === Salva file pulito ===\n",
    "out_file = \"SPDR_holdings_cleaned.xlsx\"\n",
    "all_holdings.to_excel(out_file, index=False)\n",
    "print(f\"‚úÖ File Excel pulito salvato come: {out_file}\")\n",
    "print(f\"Contiene {len(all_holdings)} righe totali.\")\n",
    "display(all_holdings.head(10))\n",
    "\n",
    "# ======================================================\n",
    "# üìà Analisi: % titoli sopra SMA200 per ETF (giorno per giorno)\n",
    "# ======================================================\n",
    "\n",
    "# Ensure etf_groups is correctly derived from all_holdings\n",
    "etf_groups = {etf: g.iloc[:,1].dropna().astype(str).tolist() for etf, g in all_holdings.groupby(\"ETF\")}\n",
    "\n",
    "sma200_daily_pct = {}\n",
    "\n",
    "print(\"\\nüìà Analisi daily % titoli sopra SMA200 per ETF...\")\n",
    "skipped_tickers_analysis = [] # List to store tickers skipped during this analysis phase\n",
    "\n",
    "# === gestione eccezioni ticker particolari e pulizia ticker non validi ===\n",
    "def fix_ticker(t):\n",
    "    t = t.strip()\n",
    "    if t == \"BF.B\": return \"BF-B\"\n",
    "    if t == \"BRK.B\": return \"BRK-B\"\n",
    "    return t\n",
    "\n",
    "for etf, tickers in etf_groups.items():\n",
    "    print(f\"\\nüìä Analisi ETF {etf} ({len(tickers)} titoli)\")\n",
    "    # Filter invalid tickers before download\n",
    "    tickers_fixed = [fix_ticker(t) for t in tickers if t != '-' and re.match(r\"^[A-Z0-9\\.\\-]{1,10}$\", t)]\n",
    "\n",
    "    if not tickers_fixed:\n",
    "        print(f\"   ‚ö† Nessun ticker valido trovato per {etf}, salto.\")\n",
    "        sma200_daily_pct[etf] = pd.Series(dtype=float)\n",
    "        continue\n",
    "\n",
    "    etf_daily_counts = {}\n",
    "    etf_daily_valid_counts = {}\n",
    "    all_dates_etf = set()\n",
    "    etf_skipped_in_analysis = []\n",
    "\n",
    "    # Download and process data for each ticker individually\n",
    "    for t in tickers_fixed:\n",
    "        try:\n",
    "            # Download data for a single ticker for the last 7 years\n",
    "            df_ticker = yf.download(t, period=\"7y\", interval=\"1d\", progress=False, auto_adjust=False)\n",
    "\n",
    "            if df_ticker.empty:\n",
    "                 print(f\"      ‚ö† Download per ticker {t} ha restituito dati vuoti, saltando.\")\n",
    "                 etf_skipped_in_analysis.append(t) # Add ticker to skipped list\n",
    "                 continue\n",
    "\n",
    "            # Check if 'Adj Close' column exists for the ticker's data\n",
    "            if 'Adj Close' not in df_ticker.columns:\n",
    "                print(f\"      ‚ö† Colonna 'Adj Close' non trovata per ticker {t}, saltando.\")\n",
    "                etf_skipped_in_analysis.append(t) # Add ticker to skipped list\n",
    "                continue\n",
    "\n",
    "            # Process the data for the single ticker\n",
    "            df_adj_close = df_ticker[\"Adj Close\"].dropna()\n",
    "\n",
    "            # Calculate SMA200 and check condition for each day\n",
    "            if len(df_adj_close) < 200:\n",
    "                print(f\"      ‚ö† Dati insufficienti per ticker {t} (<200 giorni), saltando dall'analisi daily.\")\n",
    "                etf_skipped_in_analysis.append(t) # Add ticker to skipped list if not enough data\n",
    "                continue\n",
    "\n",
    "            sma200 = df_adj_close.rolling(window=200).mean()\n",
    "\n",
    "            # Align SMA and Adj Close by date and iterate\n",
    "            aligned_data = pd.concat([df_adj_close, sma200], axis=1).dropna()\n",
    "            aligned_data.columns = ['Adj Close', 'SMA200']\n",
    "\n",
    "            all_dates_etf.update(aligned_data.index)\n",
    "\n",
    "            for date, row in aligned_data.iterrows():\n",
    "                 if date not in etf_daily_counts:\n",
    "                      etf_daily_counts[date] = 0\n",
    "                      etf_daily_valid_counts[date] = 0\n",
    "\n",
    "                 etf_daily_valid_counts[date] += 1\n",
    "                 if row['Adj Close'] > row['SMA200']:\n",
    "                      etf_daily_counts[date] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch any other errors during download or processing for this ticker\n",
    "            print(f\"      ‚ö† Errore elaborazione dati per {t}: {e}, saltando.\")\n",
    "            etf_skipped_in_analysis.append(t) # Add ticker to skipped list\n",
    "            continue\n",
    "\n",
    "    # Calculate daily percentage for the ETF after processing all individual tickers\n",
    "    all_dates_etf = sorted(list(all_dates_etf))\n",
    "    daily_percentages = {}\n",
    "    for date in all_dates_etf:\n",
    "        if date in etf_daily_valid_counts and etf_daily_valid_counts[date] > 0:\n",
    "            daily_percentages[date] = (etf_daily_counts[date] / etf_daily_valid_counts[date]) * 100\n",
    "        else:\n",
    "            # If no valid tickers for a day, set percentage to 0.0 or np.nan\n",
    "            daily_percentages[date] = 0.0 # Using 0.0 for plotting\n",
    "\n",
    "    sma200_daily_pct[etf] = pd.Series(daily_percentages).sort_index()\n",
    "    # Update the main skipped_tickers list with unique skipped tickers for this ETF\n",
    "    skipped_tickers_analysis.extend(list(set(etf_skipped_in_analysis)))\n",
    "\n",
    "    print(f\"‚úÖ Analisi daily completa per {etf}. Ticker saltati in questo ETF: {len(list(set(etf_skipped_in_analysis)))}\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "df_daily_sma200_pct = pd.DataFrame(sma200_daily_pct)\n",
    "print(\"\\nDaily % above SMA200 DataFrame:\")\n",
    "display(df_daily_sma200_pct.head())\n",
    "\n",
    "# === Stampa ticker saltati durante l'analisi ===\n",
    "if skipped_tickers_analysis:\n",
    "    print(\"\\n‚ö† Ticker saltati a causa di errori di download o elaborazione durante l'analisi daily:\")\n",
    "    for ticker in sorted(list(set(skipped_tickers_analysis))): # Print unique skipped tickers alphabetically\n",
    "        print(f\"- {ticker}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nessun ticker √® stato saltato durante l'analisi daily.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# PARAMETRI MODIFICABILI\n",
    "# ==========================================\n",
    "\n",
    "start = '2010-01-01'        # Data di inizio per il download dei dati\n",
    "holding_days = 60           # Durata in giorni della posizione long\n",
    "buy_threshold_range = range(5, 55, 1) # Range e passo per testare le soglie BUY (es: range(5, 55, 1) per 5% a 54% con passo 1)\n",
    "\n",
    "# ==========================================\n",
    "# PREPARAZIONE DATI E ANALISI PER OGNI ETF\n",
    "# ==========================================\n",
    "# Ensure etf_groups and skipped_tickers_analysis are available from the first cell\n",
    "if 'etf_groups' not in locals() or 'skipped_tickers_analysis' not in locals() or 'ETF_TARGETS' not in locals():\n",
    "    raise RuntimeError(\"Variabili 'etf_groups', 'skipped_tickers_analysis' o 'ETF_TARGETS' non trovate. Esegui prima la prima cella.\")\n",
    "\n",
    "# Dictionary to store best results for each ETF\n",
    "best_results = {}\n",
    "\n",
    "# Loop through each target ETF\n",
    "for TARGET_ETF in ETF_TARGETS:\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üöÄ Analisi Backtesting e Ottimizzazione per {TARGET_ETF}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Get the list of tickers for the TARGET_ETF from etf_groups\n",
    "    etf_tickers_from_holdings = etf_groups.get(TARGET_ETF, [])\n",
    "\n",
    "    # Filter out tickers that were skipped during the daily analysis in the first cell\n",
    "    tickers = [t for t in etf_tickers_from_holdings if t not in skipped_tickers_analysis]\n",
    "\n",
    "    if not tickers:\n",
    "        print(f\"‚ùå Nessun ticker valido trovato per {TARGET_ETF} dopo aver escluso quelli saltati nell'analisi daily.\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    index_ticker = TARGET_ETF\n",
    "\n",
    "    # DOWNLOAD DATI\n",
    "    try:\n",
    "        # Download data for all tickers at once\n",
    "        data = yf.download(tickers, start=start, period=\"max\", interval=\"1d\", progress=False, auto_adjust=False)['Adj Close']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il download dei dati dei ticker per {TARGET_ETF}: {e}\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"‚ùå Nessun dato valido scaricato per i ticker di {TARGET_ETF}.\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    # Download index data\n",
    "    try:\n",
    "        index = yf.download(index_ticker, start=start, period=\"max\", interval=\"1d\", progress=False, auto_adjust=False)['Adj Close']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il download dei dati dell'indice {index_ticker}: {e}\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    if index.empty:\n",
    "        print(f\"‚ùå Nessun dato valido scaricato per l'indice {index_ticker}.\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    # Align data and index\n",
    "    data, index = data.align(index, join='inner', axis=0)\n",
    "\n",
    "    # Filter out tickers that have become all NaNs after alignment\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    valid_tickers = data.columns.tolist()\n",
    "\n",
    "    if not valid_tickers:\n",
    "        print(f\"‚ùå Nessun ticker valido rimasto dopo l'allineamento dei dati per {TARGET_ETF}.\")\n",
    "        continue # Skip to the next ETF\n",
    "\n",
    "    print(f\"\\n‚úÖ Dati scaricati per {len(valid_tickers)} tickers validi per {TARGET_ETF}.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # CALCOLO INDICATORE (% sopra MA200)\n",
    "    # ==========================================\n",
    "    ma200 = data.rolling(200).mean()\n",
    "    # Use the length of valid_tickers AFTER alignment for the calculation\n",
    "    above200 = (data > ma200).sum(axis=1) / len(valid_tickers) * 100\n",
    "\n",
    "    # ==========================================\n",
    "    # FUNZIONE DI BACKTEST (uscita dopo X giorni - entrata su cross)\n",
    "    # ==========================================\n",
    "    def backtest_timed_exit(above200, index, buy_thr, hold_days):\n",
    "        position = 0\n",
    "        days_in_trade = 0\n",
    "        signal = pd.Series(0, index=above200.index)\n",
    "\n",
    "        for i in range(1, len(signal)):\n",
    "            # Check if the current date and previous date exist in above200 and index\n",
    "            if (signal.index[i] in above200.index and signal.index[i] in index.index and\n",
    "                signal.index[i-1] in above200.index and signal.index[i-1] in index.index): # Ensure previous day also exists in index and above200\n",
    "\n",
    "                # Entry condition: only if flat AND indicator crosses below buy_thr\n",
    "                if position == 0 and above200.iloc[i] < buy_thr and above200.iloc[i-1] >= buy_thr:\n",
    "                    position = 1\n",
    "                    days_in_trade = 0 # Reset days_in_trade on new entry\n",
    "\n",
    "                elif position == 1:\n",
    "                    days_in_trade += 1\n",
    "                    if days_in_trade >= hold_days:\n",
    "                        position = 0 # Exit after hold_days\n",
    "\n",
    "                signal.iloc[i] = position\n",
    "\n",
    "        returns = index.pct_change().fillna(0)\n",
    "        # Ensure signal is aligned to the returns index before multiplication\n",
    "        aligned_signal = signal.reindex(returns.index).fillna(0)\n",
    "        # Calculate strategy returns by multiplying index returns with the aligned signal\n",
    "        # Explicitly select the index column name from returns before multiplication\n",
    "        strategy_returns = returns.iloc[:, 0] * aligned_signal\n",
    "        # Ensure strategy is a Series before cumsum\n",
    "        strategy = strategy_returns.cumsum()\n",
    "\n",
    "        total_return = np.exp(strategy.iloc[-1]) - 1\n",
    "        cagr = (1 + total_return) ** (252 / len(index)) - 1 # Using len(index) for days in CAGR calculation\n",
    "\n",
    "        return cagr, strategy, signal\n",
    "\n",
    "    # ==========================================\n",
    "    # TEST DI VARIE SOGLIE BUY\n",
    "    # ==========================================\n",
    "    results = []\n",
    "\n",
    "    for buy in buy_threshold_range:\n",
    "        try:\n",
    "            cagr, _, _ = backtest_timed_exit(above200, index, buy, holding_days)\n",
    "            results.append((buy, cagr))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Errore durante il backtest per {TARGET_ETF} con soglia BUY={buy}%: {e}\")\n",
    "            results.append((buy, np.nan)) # Append NaN for failed backtest\n",
    "\n",
    "    df_res = pd.DataFrame(results, columns=['Buy','CAGR'])\n",
    "    # Explicitly convert CAGR to numeric, coercing errors to NaN\n",
    "    df_res['CAGR'] = pd.to_numeric(df_res['CAGR'], errors='coerce')\n",
    "    df_res = df_res.dropna().sort_values('CAGR', ascending=False)\n",
    "\n",
    "    if df_res.empty:\n",
    "        print(f\"\\n‚ùå Nessun risultato di backtest valido trovato per {TARGET_ETF}. Impossibile determinare la miglior soglia BUY.\")\n",
    "    else:\n",
    "        best = df_res.iloc[0]\n",
    "        best_results[TARGET_ETF] = best # Store the best result for this ETF\n",
    "        print(f\"\\n‚≠ê Miglior soglia BUY trovata per {TARGET_ETF} (uscita dopo\", holding_days, \"giorno/i):\")\n",
    "        print(best)\n",
    "\n",
    "        # ==========================================\n",
    "        # GRAFICO EQUITY LINE OTTIMALE\n",
    "        # ==========================================\n",
    "        _, strat, signal = backtest_timed_exit(above200, index, best.Buy, holding_days)\n",
    "        plt.figure(figsize=(12, 6)) # Increased figure size slightly\n",
    "        # Ensure plotting data is aligned\n",
    "        aligned_strat = np.exp(strat).reindex(index.index).ffill() # Use .ffill()\n",
    "        aligned_index = (index / index.iloc[0]).reindex(index.index).ffill() # Use .ffill()\n",
    "\n",
    "        plt.plot(aligned_strat, label=f'Strategy (Buy<{best.Buy}%, hold {holding_days}d, cross)')\n",
    "        plt.plot(aligned_index, label='Buy & Hold', alpha=0.5)\n",
    "        plt.title(f\"Equity line strategia breadth su {TARGET_ETF} (holding {holding_days} giorno/i, entrata su cross)\")\n",
    "        plt.xlabel(\"Date\") # Added X-axis label\n",
    "        plt.ylabel(\"Cumulative Return (Factor)\") # Added Y-axis label\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45) # Rotate x-axis labels\n",
    "        plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "        plt.show()\n",
    "\n",
    "        # ==========================================\n",
    "        # GRAFICO DELL‚ÄôINDICATORE + SEGNALI\n",
    "        # ==========================================\n",
    "        plt.figure(figsize=(12, 6)) # Increased figure size slightly\n",
    "        plt.plot(above200, label='% sopra MA200')\n",
    "        plt.axhline(best.Buy, color='red', linestyle='--', label=f'Soglia Buy {best.Buy}%')\n",
    "        # Ensure signal is aligned for plotting\n",
    "        aligned_signal = signal.reindex(above200.index).fillna(0)\n",
    "        plt.fill_between(above200.index, 0, 100, where=aligned_signal > 0, color='green', alpha=0.1, label='Posizione Long')\n",
    "        plt.title(f\"Indicatore breadth con segnali di acquisto su {TARGET_ETF} (holding {holding_days} giorno/i, entrata su cross)\")\n",
    "        plt.xlabel(\"Date\") # Added X-axis label\n",
    "        plt.ylabel(\"% Above MA200\") # Added Y-axis label\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45) # Rotate x-axis labels\n",
    "        plt.tight_layout() # Adjust layout\n",
    "        plt.show()\n",
    "\n",
    "        # ==========================================\n",
    "        # GRAFICO PERFORMANCE PER SOGLIA BUY\n",
    "        # ==========================================\n",
    "        plt.figure(figsize=(10, 6)) # Increased figure size slightly\n",
    "        plt.bar(df_res['Buy'], df_res['CAGR'])\n",
    "        plt.xlabel(f'Soglia Buy (% titoli sotto MA200 per {TARGET_ETF})')\n",
    "        plt.ylabel('CAGR')\n",
    "        plt.title(f'Performance (CAGR) per diverse soglie Buy su {TARGET_ETF}')\n",
    "        plt.xticks(df_res['Buy'], rotation=45) # Rotate x-axis labels for the bar chart too\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout() # Adjust layout\n",
    "        plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# RIEPILOGO FINALE\n",
    "# ==========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üìä Riepilogo Migliori Soglie BUY e CAGR per ETF\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "if best_results:\n",
    "    df_summary = pd.DataFrame.from_dict(best_results, orient='index')\n",
    "    df_summary.index.name = 'ETF'\n",
    "    df_summary.columns = ['Miglior Soglia BUY (%)', 'CAGR']\n",
    "    df_summary['Miglior Soglia BUY (%)'] = df_summary['Miglior Soglia BUY (%)'].astype(int) # Display as integer\n",
    "    print(df_summary.to_string())\n",
    "else:\n",
    "    print(\"‚ùå Nessun risultato valido da riepilogare.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
