{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# IMPORT & CONFIG\n",
    "# ===============================\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import display\n",
    "import io\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURAZIONE\n",
    "# ===============================\n",
    "# TICKER = \"NFLX\"  # es. AAPL # Rimosso per usare il valore dalla prima cella\n",
    "# YEARS = 8        # ultimi anni da visualizzare # Rimosso per usare il valore dalla prima cella\n",
    "\n",
    "# ===============================\n",
    "# UTILITIES\n",
    "# ===============================\n",
    "BASE_URL = \"https://discountingcashflows.com/company/{ticker}/{statement}/\"\n",
    "\n",
    "def get_table_discounting(ticker, statement):\n",
    "    url = BASE_URL.format(ticker=ticker, statement=statement)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per {statement}: {e}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        print(f\"Nessuna tabella trovata per {statement} su {url}\")\n",
    "        return None\n",
    "    for t in tables:\n",
    "        try:\n",
    "            df = pd.read_html(io.StringIO(str(t)))[0]\n",
    "            if df.shape[1] >= 2:\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    print(f\"Nessuna tabella leggibile trovata per {statement} su {url}\")\n",
    "    return None\n",
    "\n",
    "def extract_series_from_row(df, keywords):\n",
    "    if df is None: return None, None\n",
    "    periods = df.columns.tolist()[1:]\n",
    "    for kw in keywords:\n",
    "        mask = df.iloc[:,0].astype(str).str.contains(kw, case=False, na=False)\n",
    "        if mask.any():\n",
    "            row = df.loc[mask].iloc[0]\n",
    "            vals = row.iloc[1:].astype(str).replace(\"-\", np.nan).replace(\"\", np.nan)\n",
    "            cleaned_vals, cleaned_periods = [], []\n",
    "            for i, v in enumerate(vals):\n",
    "                if pd.isna(v): continue\n",
    "                s = str(v).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "                try:\n",
    "                    cleaned_vals.append(float(s))\n",
    "                    cleaned_periods.append(periods[i])\n",
    "                except:\n",
    "                    continue\n",
    "            if cleaned_vals:\n",
    "                return cleaned_vals, cleaned_periods\n",
    "    return None, None\n",
    "\n",
    "# ===============================\n",
    "# ESTRAZIONE FINANCIALS\n",
    "# ===============================\n",
    "def extract_financials(ticker):\n",
    "    financials = {}\n",
    "    # Income Statement\n",
    "    is_df = get_table_discounting(ticker, \"income-statement\")\n",
    "    financials[\"Revenue\"], financials[\"Periods\"] = extract_series_from_row(is_df, [\"Revenue\", \"Sales\", \"Total Revenue\"])\n",
    "    financials[\"NetIncome\"], _ = extract_series_from_row(is_df, [\"Net Income\", \"Net loss\", \"NetLossProfit\"])\n",
    "    # Balance Sheet\n",
    "    bs_df = get_table_discounting(ticker, \"balance-sheet-statement\")\n",
    "    financials[\"Equity\"], _ = extract_series_from_row(bs_df, [\"Total Equity\", \"Total shareholders' equity\", \"Total stockholders' equity\"])\n",
    "    financials[\"Debt\"], _ = extract_series_from_row(bs_df, [\"Total Debt\", \"Total liabilities\", \"Total Long Term Debt\"])\n",
    "    # Cash Flow Statement\n",
    "    cf_df = get_table_discounting(ticker, \"cash-flow-statement\")\n",
    "    financials[\"FCF\"], _ = extract_series_from_row(cf_df, [\"Free Cash Flow\", \"Free cash flow\", \"FreeCashFlow\", \"Operating Cash Flow\"])\n",
    "    # Check if periods extracted\n",
    "    if financials[\"Periods\"] is None:\n",
    "        print(\"Could not extract periods data. Cannot proceed with financial data processing.\")\n",
    "        return None\n",
    "    # Limit last YEARS and invert order (vecchio → recente)\n",
    "    for k in financials:\n",
    "        if k != \"Periods\" and financials[k] is not None:\n",
    "            financials[k] = financials[k][:YEARS][::-1]\n",
    "    financials[\"Periods\"] = financials[\"Periods\"][:YEARS][::-1]\n",
    "    return financials\n",
    "# ===============================\n",
    "# CALCOLO RATIOS\n",
    "# ===============================\n",
    "def calculate_ratios(financials):\n",
    "    ratios = {}\n",
    "    if financials is None: return None\n",
    "    try:\n",
    "        if financials[\"NetIncome\"] is not None and financials[\"Revenue\"] is not None and len(financials[\"NetIncome\"]) == len(financials[\"Revenue\"]):\n",
    "            ratios[\"ProfitMargin\"] = [ni/r*100 for ni,r in zip(financials[\"NetIncome\"], financials[\"Revenue\"])]\n",
    "        else:\n",
    "            ratios[\"ProfitMargin\"] = None\n",
    "    except:\n",
    "        ratios[\"ProfitMargin\"] = None\n",
    "    try:\n",
    "        if financials[\"NetIncome\"] is not None and financials[\"Equity\"] is not None and len(financials[\"NetIncome\"]) == len(financials[\"Equity\"]):\n",
    "            ratios[\"ROE\"] = [ni/e*100 for ni,e in zip(financials[\"NetIncome\"], financials[\"Equity\"])]\n",
    "        else:\n",
    "            ratios[\"ROE\"] = None\n",
    "    except:\n",
    "        ratios[\"ROE\"] = None\n",
    "    try:\n",
    "        if financials[\"Debt\"] is not None and financials[\"Equity\"] is not None and len(financials[\"Debt\"]) == len(financials[\"Equity\"]):\n",
    "            ratios[\"DebtEquity\"] = [d/e if e != 0 else np.nan for d,e in zip(financials[\"Debt\"], financials[\"Equity\"])]\n",
    "        else:\n",
    "            ratios[\"DebtEquity\"] = None\n",
    "    except:\n",
    "        ratios[\"DebtEquity\"] = None\n",
    "    return ratios\n",
    "\n",
    "# ===============================\n",
    "# ESTRAZIONE STIME NET INCOME\n",
    "# ===============================\n",
    "def get_net_income_estimates(ticker):\n",
    "    url = f\"https://discountingcashflows.com/company/{ticker}/estimates/\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "    except:\n",
    "        return None, None\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    estimates_table = None\n",
    "    for table in tables:\n",
    "        if \"Estimated Net Income\" in table.text:\n",
    "            estimates_table = table\n",
    "            break\n",
    "    if estimates_table is None: return None, None\n",
    "    try:\n",
    "        df = pd.read_html(io.StringIO(str(estimates_table)), header=None)[0]\n",
    "    except:\n",
    "        return None, None\n",
    "    idx = df[df.iloc[:,0].astype(str).str.contains(\"Estimated Net Income\", case=False, na=False)].index\n",
    "    if idx.empty: return None, None\n",
    "    low_row = df.iloc[idx[0]+1]\n",
    "    numerical_cols_values = []\n",
    "    for i in range(1, len(low_row)):\n",
    "        val = low_row.iloc[i]\n",
    "        try:\n",
    "            s = str(val).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "            numerical_values = float(s)\n",
    "            numerical_cols_values.append(numerical_values)\n",
    "        except:\n",
    "            continue\n",
    "    current_year_estimate = numerical_cols_values[0] if len(numerical_cols_values)>=1 else None\n",
    "    next_year_estimate = numerical_cols_values[1] if len(numerical_cols_values)>=2 else None\n",
    "    return current_year_estimate, next_year_estimate\n",
    "\n",
    "# ===============================\n",
    "# PLOTTAGGIO FINANCIALS + RATIOS\n",
    "# ===============================\n",
    "def plot_financials_ratios_price(financials, ratios, ticker):\n",
    "    if financials is None or ratios is None:\n",
    "        print(\"Cannot plot due to missing financial or ratio data.\")\n",
    "        return\n",
    "\n",
    "    labels = financials.get(\"Periods\", [])\n",
    "    rev = np.array(financials.get(\"Revenue\", []), dtype=float) if financials.get(\"Revenue\") is not None else np.array([])\n",
    "    ni = np.array(financials.get(\"NetIncome\", []), dtype=float) if financials.get(\"NetIncome\") is not None else np.array([])\n",
    "\n",
    "    # Adatta scala (Migliaia / Milioni)\n",
    "    factor = 1\n",
    "    max_val = 0\n",
    "    if rev.size>0: max_val=max(max_val,max(rev))\n",
    "    if ni.size>0: max_val=max(max_val,max(ni))\n",
    "    if max_val>1e6: factor=1e6\n",
    "    if rev.size>0: rev/=factor\n",
    "    if ni.size>0: ni/=factor\n",
    "    y_label_fin = \"Amount\"\n",
    "    if factor==1e6: y_label_fin+=\" (M)\"\n",
    "\n",
    "    # Ratios\n",
    "    pm = np.array(ratios.get(\"ProfitMargin\", np.zeros(len(labels))))\n",
    "    roe = np.array(ratios.get(\"ROE\", np.zeros(len(labels))))\n",
    "    de = np.array(ratios.get(\"DebtEquity\", np.zeros(len(labels))))\n",
    "\n",
    "    # ===============================\n",
    "    # PLOT FINANCIALS + RATIOS\n",
    "    # ===============================\n",
    "    fig, axs = plt.subplots(2,1, figsize=(14,10))\n",
    "    # --- Financials\n",
    "    if len(labels)==len(rev) and len(labels)==len(ni):\n",
    "        axs[0].plot(labels, rev, marker='o', label=\"Revenue\")\n",
    "        axs[0].plot(labels, ni, marker='o', label=\"Net Income\")\n",
    "        axs[0].set_title(f\"{ticker} Financials\")\n",
    "        axs[0].set_ylabel(y_label_fin)\n",
    "        axs[0].legend()\n",
    "        axs[0].grid(True)\n",
    "    else:\n",
    "        axs[0].set_title(f\"{ticker} Financials (Data Unavailable)\")\n",
    "        axs[0].text(0.5,0.5,\"Financial data not available.\", ha='center', va='center', transform=axs[0].transAxes)\n",
    "\n",
    "    # --- Ratios\n",
    "    if len(labels)==len(pm) and len(labels)==len(roe) and len(labels)==len(de):\n",
    "        axs[1].plot(labels, pm, marker='o', label=\"Profit Margin %\")\n",
    "        axs[1].plot(labels, roe, marker='o', label=\"ROE %\")\n",
    "        axs[1].plot(labels, de, marker='o', label=\"Debt/Equity\")\n",
    "        axs[1].set_title(f\"{ticker} Ratios\")\n",
    "        axs[1].set_ylabel(\"Ratio / %\")\n",
    "        axs[1].legend()\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        # Add labels to the ratio plot\n",
    "        for i, label in enumerate(labels):\n",
    "            if not np.isnan(pm[i]):\n",
    "                axs[1].text(label, pm[i], f'{pm[i]:.1f}%', ha='left', va='bottom')\n",
    "            if not np.isnan(roe[i]):\n",
    "                axs[1].text(label, roe[i], f'{roe[i]:.1f}%', ha='left', va='bottom')\n",
    "            if not np.isnan(de[i]):\n",
    "                 axs[1].text(label, de[i], f'{de[i]:.2f}', ha='left', va='bottom') # Debt/Equity as a ratio, not percentage\n",
    "\n",
    "    else:\n",
    "        axs[1].set_title(f\"{ticker} Ratios (Data Unavailable)\")\n",
    "        axs[1].text(0.5,0.5,\"Ratio data not available.\", ha='center', va='center', transform=axs[1].transAxes)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Added calls to get financial data and ratio data first\n",
    "financial_data = extract_financials(TICKER)\n",
    "ratio_data = calculate_ratios(financial_data)\n",
    "plot_financials_ratios_price(financial_data, ratio_data, TICKER)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ===============================\n",
    "# TERZO BLOCCO: NET INCOME + STOCK PRICE (assi X/Y corretti)\n",
    "# ===============================\n",
    "\n",
    "# Creazione DataFrame Net Income storico + stime\n",
    "historical_ni = financial_data.get(\"NetIncome\", [])\n",
    "historical_periods = financial_data.get(\"Periods\", [])\n",
    "\n",
    "historical_data_with_years = []\n",
    "if historical_ni and historical_periods and len(historical_ni) == len(historical_periods):\n",
    "    for period, ni in zip(historical_periods, historical_ni):\n",
    "        try:\n",
    "            year = int(pd.to_datetime(period).year)\n",
    "            historical_data_with_years.append({'Year': year, 'Net Income': ni, 'Type': 'Historical'})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Estrazione stime Net Income\n",
    "estimate_for_2025 = None\n",
    "estimate_for_2026 = None\n",
    "\n",
    "url = f\"https://discountingcashflows.com/company/{TICKER}/estimates/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "try:\n",
    "    r = requests.get(url, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    estimates_table = None\n",
    "    for table in tables:\n",
    "        if \"Estimated Net Income\" in table.text:\n",
    "            estimates_table = table\n",
    "            break\n",
    "\n",
    "    if estimates_table:\n",
    "        df_estimates = pd.read_html(io.StringIO(str(estimates_table)), header=None)[0]\n",
    "        estimated_net_income_row_index = df_estimates[df_estimates.iloc[:, 0].astype(str).str.contains(\"Estimated Net Income\", case=False, na=False)].index\n",
    "\n",
    "        if not estimated_net_income_row_index.empty:\n",
    "            low_row_index = estimated_net_income_row_index[0] + 1\n",
    "            low_row = df_estimates.iloc[low_row_index]\n",
    "\n",
    "            numerical_cols_values = []\n",
    "            for i in range(1, len(low_row)):\n",
    "                val = low_row.iloc[i]\n",
    "                try:\n",
    "                    s = str(val).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "                    numerical_values = float(s)\n",
    "                    numerical_cols_values.append(numerical_values)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # 5° valore → stima 2025, 4° valore → stima 2026\n",
    "            if len(numerical_cols_values) > 4: estimate_for_2025 = numerical_cols_values[4]\n",
    "            if len(numerical_cols_values) > 3: estimate_for_2026 = numerical_cols_values[3]\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Aggiungi le stime\n",
    "estimated_data = []\n",
    "if estimate_for_2025 is not None: estimated_data.append({'Year': 2025, 'Net Income': estimate_for_2025, 'Type': 'Estimated'})\n",
    "if estimate_for_2026 is not None: estimated_data.append({'Year': 2026, 'Net Income': estimate_for_2026, 'Type': 'Estimated'})\n",
    "\n",
    "# Combina storico + stimato\n",
    "ni_df = pd.DataFrame(historical_data_with_years + estimated_data).sort_values(by='Year').reset_index(drop=True)\n",
    "\n",
    "# ===============================\n",
    "# Stock Price\n",
    "# ===============================\n",
    "stock_data = pd.DataFrame()  # Initialize stock_data as an empty DataFrame\n",
    "price_col = None # Initialize price_col to None\n",
    "\n",
    "try:\n",
    "    start_date_stock = (datetime.now() - timedelta(days=YEARS * 365 * 1.1)).strftime('%Y-%m-%d') # Fetch slightly more than YEARS to ensure coverage\n",
    "    end_date_stock = datetime.now().strftime('%Y-%m-%d')\n",
    "    stock_data = yf.download(TICKER, start=start_date_stock, end=end_date_stock, progress=False, auto_adjust=False) # Added auto_adjust=False\n",
    "\n",
    "    if not stock_data.empty:\n",
    "        # Scegli la colonna prezzo\n",
    "        if 'Adj Close' in stock_data.columns:\n",
    "            price_col = 'Adj Close'\n",
    "        elif 'Close' in stock_data.columns:\n",
    "            price_col = 'Close'\n",
    "        else:\n",
    "            print(\"Nessuna colonna Close/Adj Close trovata nei dati delle azioni.\")\n",
    "            stock_data = pd.DataFrame() # Imposta stock_data a un DataFrame vuoto se non ci sono colonne di prezzo valide\n",
    "            price_col = None\n",
    "\n",
    "        # Filter stock_data to include only the last YEARS if stock_data is not empty\n",
    "        if not stock_data.empty:\n",
    "            start_date_filter = datetime.now() - timedelta(days=YEARS * 365)\n",
    "            stock_data = stock_data[stock_data.index >= start_date_filter]\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Errore fetching stock data:\", e)\n",
    "    # If fetching stock data fails, stock_data and price_col remain as initialized empty DataFrame and None\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# PLOT\n",
    "# ===============================\n",
    "fig, ax3 = plt.subplots(figsize=(14,6))\n",
    "\n",
    "# Linea arancione: Historical Net Income\n",
    "hist_ni = ni_df[ni_df['Type'] == 'Historical']\n",
    "ax3.plot(pd.to_datetime(hist_ni['Year'].astype(str) + \"-12-31\"),\n",
    "         hist_ni['Net Income'], marker='o', color='orange', label='Historical Net Income')\n",
    "\n",
    "# Linea rossa tratteggiata: Estimated Net Income\n",
    "est_ni = ni_df[ni_df['Type'] == 'Estimated']\n",
    "ax3.plot(pd.to_datetime(est_ni['Year'].astype(str) + \"-12-31\"),\n",
    "         est_ni['Net Income'], marker='o', color='red', linestyle='--', label='Estimated Net Income')\n",
    "\n",
    "# Linea di continuità tra ultimo storico e prima stima\n",
    "if not hist_ni.empty and not est_ni.empty:\n",
    "    last_hist_date = pd.to_datetime(hist_ni['Year'].iloc[-1].astype(str) + \"-12-31\")\n",
    "    last_hist_value = hist_ni['Net Income'].iloc[-1]\n",
    "    first_est_date = pd.to_datetime(est_ni['Year'].iloc[0].astype(str) + \"-12-31\")\n",
    "    first_est_value = est_ni['Net Income'].iloc[0]\n",
    "    ax3.plot([last_hist_date, first_est_date], [last_hist_value, first_est_value],\n",
    "             color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax3.set_xlabel(\"Year\")\n",
    "ax3.set_ylabel(\"Net Income\")\n",
    "ax3.set_title(f\"{TICKER} Net Income + Stock Price\")\n",
    "ax3.grid(True)\n",
    "ax3.legend(loc='upper left')\n",
    "\n",
    "# ===============================\n",
    "# Stock Price su asse Y destro (stesso X di Net Income)\n",
    "# ===============================\n",
    "if 'stock_data' in globals() and not stock_data.empty and price_col in stock_data.columns:\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(stock_data.index, stock_data[price_col], color='blue', alpha=0.5, label='Stock Price')\n",
    "    ax4.set_ylabel(\"Stock Price\")\n",
    "    ax4.legend(loc='upper right')\n",
    "    # Allineiamo X\n",
    "    min_date = min(pd.to_datetime(hist_ni['Year'].iloc[0].astype(str) + \"-12-31\"), stock_data.index.min())\n",
    "    max_date = max(pd.to_datetime(est_ni['Year'].iloc[-1].astype(str) + \"-12-31\"), stock_data.index.max())\n",
    "    ax3.set_xlim(min_date, max_date)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# IMPORT & CONFIG\n",
    "# ===============================\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from IPython.display import display\n",
    "import io\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURAZIONE\n",
    "# ===============================\n",
    "TICKER = \"STMMI.MI\"  # es. AAPL\n",
    "YEARS = 4        # ultimi anni da visualizzare\n",
    "\n",
    "# ===============================\n",
    "# BASE URL\n",
    "# ===============================\n",
    "BASE_URL = \"https://discountingcashflows.com/company/{ticker}/{statement}/\"\n",
    "\n",
    "# ===============================\n",
    "# FUNZIONI DI BASE\n",
    "# ===============================\n",
    "def get_table_discounting(ticker, statement):\n",
    "    url = BASE_URL.format(ticker=ticker, statement=statement)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per {statement}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        print(f\"Nessuna tabella trovata per {statement} su {url}\")\n",
    "        return None\n",
    "    for t in tables:\n",
    "        try:\n",
    "            df = pd.read_html(io.StringIO(str(t)))[0]\n",
    "            if df.shape[1] >= 2:\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_value(df, keywords):\n",
    "    if df is None:\n",
    "        return 0\n",
    "    for keyword in keywords:\n",
    "        mask = df.iloc[:, 0].astype(str).str.contains(keyword, case=False, na=False)\n",
    "        if mask.any():\n",
    "            row = df[mask].iloc[0, 1:].dropna()\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            val = row.iloc[0]\n",
    "            if isinstance(val, str):\n",
    "                # Remove commas, parentheses, and handle negative numbers in parentheses\n",
    "                val = float(re.sub(r'[(),]', '', val.replace(',', '').replace('(', '-').replace(')', '')))\n",
    "            return float(val)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def extract_row(df, keywords):\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    periods = df.columns.tolist()[1:]\n",
    "    for kw in keywords:\n",
    "        mask = df.iloc[:, 0].astype(str).str.contains(kw, case=False, na=False)\n",
    "        if mask.any():\n",
    "            row = df.loc[mask].iloc[0]\n",
    "            vals = row.iloc[1:].astype(str).replace(\"-\", np.nan).replace(\"\", np.nan)\n",
    "            cleaned_vals, cleaned_periods = [], []\n",
    "            for i, v in enumerate(vals):\n",
    "                if pd.isna(v):\n",
    "                    cleaned_vals.append(np.nan)\n",
    "                    cleaned_periods.append(periods[i])\n",
    "                else:\n",
    "                    try:\n",
    "                        s = str(v).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "                        cleaned_vals.append(float(s))\n",
    "                        cleaned_periods.append(periods[i])\n",
    "                    except:\n",
    "                        cleaned_vals.append(np.nan)\n",
    "                        cleaned_periods.append(periods[i])\n",
    "            return cleaned_vals, cleaned_periods\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def extract_market_cap_and_shares_from_overview(ticker):\n",
    "    \"\"\"\n",
    "    Estrae Market Cap e Shares Outstanding dalla pagina overview.\n",
    "    Ritorna i valori numerici e gli indicatori di scala.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(ticker=ticker, statement=\"overview\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per overview: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    market_cap_value, market_cap_scale_indicator = None, None\n",
    "    shares_outstanding_value, shares_outstanding_scale_indicator = None, None\n",
    "\n",
    "    # Estrai Market Cap\n",
    "    market_cap_text_element = soup.find(string=lambda text: text and \"Market Cap\" in text)\n",
    "    if market_cap_text_element:\n",
    "        value_element = market_cap_text_element.find_next()\n",
    "        if value_element:\n",
    "            raw_value_text = value_element.text.strip()\n",
    "            match = re.search(r'([\\d,]+\\.?\\d*)\\s*(Bil|Mil|Thou|billion|million|thousand)?', raw_value_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                value_str = match.group(1).replace(',', '')\n",
    "                market_cap_scale_indicator = match.group(2)\n",
    "                try:\n",
    "                    market_cap_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    pass # Keep as None\n",
    "\n",
    "    # Estrai Shares Outstanding - cerca vicino a Market Cap o come voce separata\n",
    "    shares_outstanding_text_element = soup.find(string=lambda text: text and (\"Shares Outstanding\" in text or \"Shares\" in text))\n",
    "    if shares_outstanding_text_element:\n",
    "         value_element = shares_outstanding_text_element.find_next()\n",
    "         if value_element:\n",
    "            raw_value_text = value_element.text.strip()\n",
    "            match = re.search(r'([\\d,]+\\.?\\d*)\\s*(Bil|Mil|Thou|billion|million|thousand)?', raw_value_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                value_str = match.group(1).replace(',', '')\n",
    "                shares_outstanding_scale_indicator = match.group(2)\n",
    "                try:\n",
    "                    shares_outstanding_value = float(value_str)\n",
    "                except ValueError:\n",
    "                    pass # Keep as None\n",
    "\n",
    "\n",
    "    return market_cap_value, market_cap_scale_indicator, shares_outstanding_value, shares_outstanding_scale_indicator\n",
    "\n",
    "\n",
    "def get_market_cap_and_shares_values(ticker):\n",
    "    \"\"\"\n",
    "    Combina estrazione Market Cap e Shares Outstanding dall'overview.\n",
    "    Ritorna i valori numerici e i loro indicatori di scala.\n",
    "    \"\"\"\n",
    "    market_cap_value, market_cap_scale_indicator, shares_outstanding_value, shares_outstanding_scale_indicator = extract_market_cap_and_shares_from_overview(ticker)\n",
    "\n",
    "\n",
    "    # Fallback to income statement if shares not found in overview\n",
    "    if shares_outstanding_value is None or np.isnan(shares_outstanding_value):\n",
    "         is_df = get_table_discounting(ticker, \"income-statement\")\n",
    "         so_full, so_periods_full = extract_row(is_df, [\n",
    "            \"Diluted Weighted Average Shares Outstanding\",\n",
    "            \"Weighted Average Shares Outstanding\",\n",
    "            \"Shares Outstanding\",\n",
    "            \"Common Stock Shares Outstanding\",\n",
    "            \"Weighted Average Shares\",\n",
    "            \"Common Stock Shares\"\n",
    "         ])\n",
    "         shares_outstanding_value = so_full[0] if so_full and len(so_full) > 0 else np.nan\n",
    "         shares_outstanding_scale_indicator = None # Reset scale indicator if using fallback\n",
    "\n",
    "\n",
    "    return market_cap_value, market_cap_scale_indicator, shares_outstanding_value, shares_outstanding_scale_indicator\n",
    "\n",
    "def get_last_two_periods_data(values, periods):\n",
    "    \"\"\"\n",
    "    Given a list of values and periods (most recent first),\n",
    "    returns the value and period for the last two available periods,\n",
    "    including LTM if present.\n",
    "    \"\"\"\n",
    "    if values is None or periods is None or len(values) < 2 or len(values) != len(periods):\n",
    "        return None, None, None, None # Need at least 2 values and matching periods\n",
    "\n",
    "    # values and periods are already sorted most recent first from extract_row\n",
    "    latest_value, latest_period = values[0], periods[0]\n",
    "    previous_value, previous_period = values[1], periods[1]\n",
    "\n",
    "    return latest_value, latest_period, previous_value, previous_period\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CALCOLO YIELD\n",
    "# ===============================\n",
    "def calculate_shareholder_yield(ticker):\n",
    "    print(f\"--- Estrazione dati per {ticker} ---\")\n",
    "    cf_df = get_table_discounting(ticker, \"cash-flow-statement\")\n",
    "\n",
    "    if cf_df is None:\n",
    "        print(f\"❌ Cash Flow non trovato per {ticker}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Estrai Market Cap e Shares Outstanding dal sito\n",
    "    market_cap_value, market_cap_scale_indicator, shares_outstanding_value, shares_outstanding_scale_indicator = get_market_cap_and_shares_values(ticker)\n",
    "\n",
    "\n",
    "    # Prezzo attuale e EPS/PE da Yahoo Finance\n",
    "    current_price = None\n",
    "    eps_value = None\n",
    "    pe_ratio_value = None\n",
    "\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        current_price = info.get('regularMarketPrice')\n",
    "        eps_value = info.get('trailingEps') # Or forwardEps depending on preference\n",
    "        pe_ratio_value = info.get('trailingPE') # Or forwardPE depending on preference\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'estrazione da Yahoo Finance: {e}\")\n",
    "\n",
    "\n",
    "    # Estrazione valori Cash Flow (dal sito originale)\n",
    "    dividends = abs(extract_value(cf_df, [\"Dividends Paid\"]))\n",
    "    buyback = abs(extract_value(cf_df, [\"Repurchase\", \"Common Stock Repurchased\"]))\n",
    "    issuance = abs(extract_value(cf_df, [\"Issuance of Stock\", \"Common Stock Issued\"]))\n",
    "    # Keep Debt Repayment extraction for the original Shareholder Yield calculation - EXTRACT WITHOUT ABS\n",
    "    debt_repayment_cf = extract_value(cf_df, [\"Debt Repayment\"]) # Extract without absolute value\n",
    "\n",
    "\n",
    "    # Calcolo per azione (usando i valori estratti direttamente, assumendo scala coerente)\n",
    "    shareholder_y = None\n",
    "    dividend_y = None\n",
    "    buyback_y = None\n",
    "\n",
    "\n",
    "    if current_price is not None and isinstance(current_price, (int, float)) and shares_outstanding_value is not None and not np.isnan(shares_outstanding_value) and shares_outstanding_value != 0 and market_cap_value is not None:\n",
    "\n",
    "        # Usiamo i values extracted directly, assuming they are in the same scale\n",
    "        # The values extracted from the website are likely in millions or billions,\n",
    "        # while shares outstanding is also in millions or billions.\n",
    "        # The per share calculation needs to account for the scale difference.\n",
    "        # Let's use the Market Cap as the base for the yield calculation,\n",
    "        # as it is directly comparable to the financial statement values (assuming they are in the same scale).\n",
    "        # We need to convert the market cap to the same scale as the financial statement values.\n",
    "\n",
    "        # Determine the scale factor based on the financial data extracted (Dividends, Buyback, Issuance, Debt Repayment)\n",
    "        # Assume the scale of these values is consistent. We need to infer it.\n",
    "        # A simple heuristic: check the magnitude of the values relative to the reported scale indicator of Shares Outstanding or Market Cap.\n",
    "        # A more robust approach would be to look for scale indicators on the financial statement tables, but the function `get_table_discounting` doesn't extract this.\n",
    "        # For now, let's assume the financial statement values (Dividends, Buyback, Issuance, Debt Repayment) are in the same scale as indicated by the Shares Outstanding.\n",
    "\n",
    "        financial_data_scale_factor = 1.0\n",
    "        if shares_outstanding_scale_indicator:\n",
    "             if shares_outstanding_scale_indicator.lower() in ['bil', 'billion']:\n",
    "                 financial_data_scale_factor = 1e9\n",
    "             elif shares_outstanding_scale_indicator.lower() in ['mil', 'million']:\n",
    "                 financial_data_scale_factor = 1e6\n",
    "             elif shares_outstanding_scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                 financial_data_scale_factor = 1e3\n",
    "             else:\n",
    "                  financial_data_scale_factor = 1.0\n",
    "        # If no shares outstanding scale indicator, try market cap scale indicator\n",
    "        elif market_cap_scale_indicator:\n",
    "             if market_cap_scale_indicator.lower() in ['bil', 'billion']:\n",
    "                 financial_data_scale_factor = 1e9\n",
    "             elif market_cap_scale_indicator.lower() in ['mil', 'million']:\n",
    "                 financial_data_scale_factor = 1e6\n",
    "             elif market_cap_scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                 financial_data_scale_factor = 1e3\n",
    "             else:\n",
    "                  financial_data_scale_factor = 1.0\n",
    "        else:\n",
    "             # If no scale indicator found, assume the values are in the base unit (e.g., USD)\n",
    "             financial_data_scale_factor = 1.0\n",
    "\n",
    "\n",
    "        # Scale the Market Cap to match the financial data scale\n",
    "        market_cap_scaled = np.nan\n",
    "        if market_cap_value is not None and market_cap_scale_indicator:\n",
    "            mc_scale_factor = 1.0\n",
    "            if market_cap_scale_indicator.lower() in ['bil', 'billion']:\n",
    "                 mc_scale_factor = 1e9\n",
    "            elif market_cap_scale_indicator.lower() in ['mil', 'million']:\n",
    "                 mc_scale_factor = 1e6\n",
    "            elif market_cap_scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                 mc_scale_factor = 1e3\n",
    "\n",
    "            if financial_data_scale_factor != 0:\n",
    "                 market_cap_scaled = market_cap_value * (mc_scale_factor / financial_data_scale_factor)\n",
    "            else:\n",
    "                market_cap_scaled = np.nan\n",
    "        # If market cap value is present but no indicator, assume it's in the same scale as inferred financial data\n",
    "        elif market_cap_value is not None:\n",
    "             market_cap_scaled = market_cap_value # Assume same scale if no indicator\n",
    "\n",
    "        else:\n",
    "            market_cap_scaled = np.nan\n",
    "\n",
    "\n",
    "        if market_cap_scaled is not None and not np.isnan(market_cap_scaled) and market_cap_scaled != 0:\n",
    "             dividends_scaled = dividends if not np.isnan(dividends) else 0\n",
    "             buyback_scaled = buyback if not np.isnan(buyback) else 0\n",
    "             issuance_scaled = issuance if not np.isnan(issuance) else 0\n",
    "             # Use the Debt Repayment from CF, apply the correct sign logic for the original calculation\n",
    "             debt_component_scaled = -debt_repayment_cf if not np.isnan(debt_repayment_cf) else 0 # If positive (issuance), subtract; if negative (repayment), add (by subtracting the negative)\n",
    "\n",
    "\n",
    "             # Recalculate Shareholder Yield based on scaled values and Market Cap\n",
    "             shareholder_y_original = ((dividends_scaled + (buyback_scaled - issuance_scaled) + debt_component_scaled) / market_cap_scaled) * 100\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"⚠️ Market Cap Scaled is not available or is zero. Cannot calculate Shareholder Yield.\")\n",
    "            shareholder_y_original = np.nan\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ Dati insufficienti per calcolare Yields (Prezzo attuale, Shares Outstanding, o Market Cap mancanti).\")\n",
    "        shareholder_y_original = np.nan\n",
    "\n",
    "\n",
    "    # Formatta Market Cap per la visualizzazione\n",
    "    formatted_market_cap = \"N/A\"\n",
    "    if market_cap_value is not None:\n",
    "        if market_cap_scale_indicator:\n",
    "             if market_cap_scale_indicator.lower() in ['bil', 'billion']:\n",
    "                 formatted_market_cap = f\"{round(market_cap_value, 2)} Bil\"\n",
    "             elif market_cap_scale_indicator.lower() in ['mil', 'million']:\n",
    "                 formatted_market_cap = f\"{round(market_cap_value, 2)} Mil\"\n",
    "             elif market_cap_scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                 formatted_market_cap = f\"{round(market_cap_value, 2)} Thou\"\n",
    "             else:\n",
    "                 # Fallback se l'indicatore non è standard ma il valore è presente\n",
    "                 if market_cap_value >= 1e9:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e9, 2)} Bil (stima)\"\n",
    "                 elif market_cap_value >= 1e6:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e6, 2)} Mil (stima)\"\n",
    "                 elif market_cap_value >= 1e3:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e3, 2)} Thou (stima)\"\n",
    "                 else:\n",
    "                     formatted_market_cap = f\"{market_cap_value:,.0f}\"\n",
    "        else:\n",
    "             # Tentativo di formattare anche senza indicatore esplicito dall'overview\n",
    "             if market_cap_value is not None:\n",
    "                 if market_cap_value >= 1e9:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e9, 2)} Bil (stima)\"\n",
    "                 elif market_cap_value >= 1e6:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e6, 2)} Mil (stima)\"\n",
    "                 elif market_cap_value >= 1e3:\n",
    "                     formatted_market_cap = f\"{round(market_cap_value / 1e3, 2)} Thou (stima)\"\n",
    "                 else:\n",
    "                     formatted_market_cap = f\"{market_cap_value:,.0f}\"\n",
    "\n",
    "\n",
    "    # Formatta Shares Outstanding per la visualizzazione\n",
    "    formatted_shares_outstanding = \"N/A\"\n",
    "    if shares_outstanding_value is not None and not np.isnan(shares_outstanding_value):\n",
    "        if shares_outstanding_scale_indicator:\n",
    "             if shares_outstanding_scale_indicator.lower() in ['bil', 'billion']:\n",
    "                 formatted_shares_outstanding = f\"{round(shares_outstanding_value, 2)} Bil\"\n",
    "             elif shares_outstanding_scale_indicator.lower() in ['mil', 'million']:\n",
    "                 formatted_shares_outstanding = f\"{round(shares_outstanding_value, 2)} Mil\"\n",
    "             elif shares_outstanding_scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                 formatted_shares_outstanding = f\"{round(shares_outstanding_value, 2)} Thou\"\n",
    "             else:\n",
    "                 # Fallback se l'indicatore non è standard ma il valore è presente\n",
    "                 if shares_outstanding_value >= 1e9:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e9, 2)} Bil (stima)\"\n",
    "                 elif shares_outstanding_value >= 1e6:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e6, 2)} Mil (stima)\"\n",
    "                 elif shares_outstanding_value >= 1e3:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e3, 2)} Thou (stima)\"\n",
    "                 else:\n",
    "                     formatted_shares_outstanding = f\"{shares_outstanding_value:,.0f}\"\n",
    "\n",
    "        else:\n",
    "             # Fallback to heuristic if no indicator is extracted\n",
    "             if shares_outstanding_value is not None and not np.isnan(shares_outstanding_value):\n",
    "                 if shares_outstanding_value >= 1e9:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e9, 2)} Bil (stima)\"\n",
    "                 elif shares_outstanding_value >= 1e6:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e6, 2)} Mil (stima)\"\n",
    "                 elif shares_outstanding_value >= 1e3:\n",
    "                     formatted_shares_outstanding = f\"{round(shares_outstanding_value / 1e3, 2)} Thou (stima)\"\n",
    "                 else:\n",
    "                     formatted_shares_outstanding = f\"{shares_outstanding_value:,.0f}\"\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Ticker\": ticker,\n",
    "        \"Current Price\": round(current_price, 2) if isinstance(current_price, (int, float)) else \"N/A\",\n",
    "        \"Shares Outstanding\": formatted_shares_outstanding, # Usa il valore formattato\n",
    "        \"Market Cap\": formatted_market_cap, # Usa il valore formattato\n",
    "        \"Dividends\": dividends if not np.isnan(dividends) else \"N/A\", # Use extracted values, handle NaN\n",
    "        \"Buyback\": buyback if not np.isnan(buyback) else \"N/A\", # Use extracted values, handle NaN\n",
    "        \"Issuance\": issuance if not np.isnan(issuance) else \"N/A\", # Use extracted values, handle NaN\n",
    "        \"Debt Repayment (CF)\": debt_repayment_cf if not np.isnan(debt_repayment_cf) else \"N/A\", # Keep Debt Repayment from CF (raw value)\n",
    "        \"Shareholder Yield (%)\": round(shareholder_y_original, 2) if shareholder_y_original is not None and not np.isnan(shareholder_y_original) else \"N/A\", # Ridenominato per chiarezza\n",
    "        \"EPS\": round(eps_value, 2) if isinstance(eps_value, (int, float)) else \"N/A\", # Aggiunto EPS da Yahoo Finance\n",
    "        \"PE Ratio\": round(pe_ratio_value, 2) if isinstance(pe_ratio_value, (int, float)) else \"N/A\" # Aggiunto PE Ratio da Yahoo Finance\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ESECUZIONE\n",
    "# ===============================\n",
    "result = calculate_shareholder_yield(TICKER)\n",
    "\n",
    "# Mostra EPS e PE prima della tabella principale\n",
    "# Modificato per mostrare N/A solo se i valori non sono stati trovati\n",
    "if result.get('EPS') == 'N/A':\n",
    "    print(\"⚠️ EPS non trovato (finale)\")\n",
    "else:\n",
    "    print(f\"EPS: {result.get('EPS')} - Fonte: Yahoo Finance\")\n",
    "\n",
    "if result.get('PE Ratio') == 'N/A':\n",
    "    print(\"⚠️ PE Ratio non trovato (finale)\")\n",
    "else:\n",
    "    print(f\"PE Ratio: {result.get('PE Ratio')} - Fonte: Yahoo Finance\")\n",
    "\n",
    "print(\"-\" * 30) # Separatore per chiarezza\n",
    "\n",
    "# Prepare data for the main table, including the new components and the calculated shareholder yield\n",
    "result_for_table = {\n",
    "    \"Ticker\": result.get(\"Ticker\"),\n",
    "    \"Current Price\": result.get(\"Current Price\"),\n",
    "    \"Shares Outstanding\": result.get(\"Shares Outstanding\"),\n",
    "    \"Market Cap\": result.get(\"Market Cap\"),\n",
    "    \"Dividends\": result.get(\"Dividends\"),\n",
    "    \"Buyback\": result.get(\"Buyback\"),\n",
    "    \"Issuance\": result.get(\"Issuance\"),\n",
    "    \"Debt Repayment (CF)\": result.get(\"Debt Repayment (CF)\"), # Keep Debt Repayment from CF\n",
    "    \"Shareholder Yield (%)\": result.get(\"Shareholder Yield (%)\") # Ridenominato\n",
    "}\n",
    "\n",
    "\n",
    "display(pd.DataFrame([result_for_table])) # Commented out to remove table display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 📊 ANALISI BUYBACK AZIONI - COMPLETO\n",
    "# ==============================================\n",
    "\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "# ===============================\n",
    "# CONFIGURAZIONE\n",
    "# ===============================\n",
    "# Usa i valori definiti nella prima cella\n",
    "# TICKER = \"AAPL\"   # cambia ticker # Rimosso per usare il valore dalla prima cella\n",
    "# YEARS = 8         # numero di anni da visualizzare # Rimosso per usare il valore dalla prima cella\n",
    "DILUTED = False   # False → Weighted Average Shares, True → Diluted Weighted Average Shares\n",
    "\n",
    "# ===============================\n",
    "# FUNZIONI BASE\n",
    "# ===============================\n",
    "BASE_URL = \"https://discountingcashflows.com/company/{ticker}/{statement}/\"\n",
    "\n",
    "def get_table_discounting(ticker, statement):\n",
    "    \"\"\"Scarica e restituisce la tabella HTML di uno statement da discountingcashflows.com\"\"\"\n",
    "    url = BASE_URL.format(ticker=ticker, statement=statement)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per {statement}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        print(f\"Nessuna tabella trovata per {statement} su {url}\")\n",
    "        return None\n",
    "\n",
    "    for t in tables:\n",
    "        try:\n",
    "            df = pd.read_html(io.StringIO(str(t)))[0]\n",
    "            if df.shape[1] >= 2:\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f\"Nessuna tabella leggibile trovata per {statement} su {url}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_series_from_row(df, keywords):\n",
    "    \"\"\"Cerca nel dataframe una riga contenente una delle keyword e restituisce valori e periodi.\"\"\"\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    periods = df.columns.tolist()[1:]\n",
    "    for kw in keywords:\n",
    "        mask = df.iloc[:, 0].astype(str).str.contains(kw, case=False, na=False)\n",
    "        if mask.any():\n",
    "            row = df.loc[mask].iloc[0]\n",
    "            vals = row.iloc[1:].astype(str).replace(\"-\", np.nan).replace(\"\", np.nan)\n",
    "            cleaned_vals, cleaned_periods = [], []\n",
    "            for i, v in enumerate(vals):\n",
    "                if pd.isna(v):\n",
    "                    continue\n",
    "                s = str(v).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "                try:\n",
    "                    cleaned_vals.append(float(s))\n",
    "                    cleaned_periods.append(periods[i])\n",
    "                except:\n",
    "                    continue\n",
    "            if cleaned_vals:\n",
    "                return cleaned_vals, cleaned_periods\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ANALISI BUYBACK\n",
    "# ===============================\n",
    "def analyze_share_count_trend_income(ticker, years=8, diluted=False):\n",
    "    # Estrae l'Income Statement\n",
    "    is_df = get_table_discounting(ticker, \"income-statement\")\n",
    "\n",
    "    # Keyword da cercare\n",
    "    if diluted:\n",
    "        keywords = [\"Diluted Weighted Average Shares Outstanding\"]\n",
    "    else:\n",
    "        keywords = [\"Weighted Average Shares Outstanding\"]\n",
    "\n",
    "    shares, periods = extract_series_from_row(is_df, keywords)\n",
    "\n",
    "    if shares is None or len(shares) < 2:\n",
    "        print(f\"📉 Non disponibili dati sufficienti per analizzare le azioni in circolazione di {ticker}\")\n",
    "        return None\n",
    "\n",
    "    # Normalizza (vecchio → recente)\n",
    "    shares = shares[::-1]\n",
    "    periods = periods[::-1]\n",
    "\n",
    "    # Limita agli ultimi years\n",
    "    shares = shares[-years:]\n",
    "    periods = periods[-years:]\n",
    "\n",
    "    # Calcola variazione percentuale\n",
    "    variation = (shares[-1] - shares[0]) / shares[0] * 100\n",
    "\n",
    "    print(f\"\\n📊 Analisi numero azioni in circolazione per {ticker}\")\n",
    "    print(f\"Periodo analizzato: {periods[0]} → {periods[-1]}\")\n",
    "    print(f\"Azioni (inizio → fine): {shares[0]:,.0f} → {shares[-1]:,.0f}\")\n",
    "    print(f\"Variazione: {variation:.2f}%\")\n",
    "\n",
    "    # Interpretazione\n",
    "    if variation < -3:\n",
    "        print(\"🟢 Possibile BUYBACK (riduzione significativa delle azioni in circolazione)\")\n",
    "    elif variation > 3:\n",
    "        print(\"🔴 Possibile DILUIZIONE (aumento delle azioni in circolazione)\")\n",
    "    else:\n",
    "        print(\"🟡 Numero di azioni stabile negli ultimi anni\")\n",
    "\n",
    "    # ===============================\n",
    "    # GRAFICO\n",
    "    # ===============================\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(periods, shares, marker=\"o\", linewidth=2)\n",
    "    plt.title(f\"📈 Andamento azioni in circolazione - {ticker}\")\n",
    "    plt.xlabel(\"Anno\")\n",
    "    plt.ylabel(\"Azioni (unità)\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"Periods\": periods, \"Shares\": shares, \"Variation(%)\": variation}\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ESECUZIONE\n",
    "# ===============================\n",
    "result = analyze_share_count_trend_income(TICKER, YEARS, DILUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPORT & CONFIG\n",
    "# ==========================================\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURAZIONE\n",
    "# ==========================================\n",
    "# Usa i valori definiti nella prima cella\n",
    "# TICKER = \"AAPL\"     # <-- cambia qui il ticker\n",
    "# YEARS = 8            # ultimi anni da analizzare\n",
    "\n",
    "# ==========================================\n",
    "# UTILITIES\n",
    "# ==========================================\n",
    "BASE_URL = \"https://discountingcashflows.com/company/{ticker}/{statement}/\"\n",
    "\n",
    "def get_table_discounting(ticker, statement):\n",
    "    url = BASE_URL.format(ticker=ticker, statement=statement)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per {statement}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        print(f\"Nessuna tabella trovata per {statement} su {url}\")\n",
    "        return None\n",
    "    for t in tables:\n",
    "        try:\n",
    "            df = pd.read_html(io.StringIO(str(t)))[0]\n",
    "            if df.shape[1] >= 2:\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def extract_row(df, keywords):\n",
    "    if df is None:\n",
    "        return None, None  # Return None for both values and periods\n",
    "    periods = df.columns.tolist()[1:]\n",
    "    for kw in keywords:\n",
    "        mask = df.iloc[:, 0].astype(str).str.contains(kw, case=False, na=False)\n",
    "        if mask.any():\n",
    "            row = df.loc[mask].iloc[0]\n",
    "            vals = row.iloc[1:].astype(str).replace(\"-\", np.nan).replace(\"\", np.nan)\n",
    "            cleaned_vals = []\n",
    "            cleaned_periods = []\n",
    "            for i, v in enumerate(vals):\n",
    "                if pd.isna(v):\n",
    "                    cleaned_vals.append(np.nan)\n",
    "                    cleaned_periods.append(periods[i]) # Keep period even if value is NaN\n",
    "                else:\n",
    "                    try:\n",
    "                        s = str(v).replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").strip()\n",
    "                        cleaned_vals.append(float(s))\n",
    "                        cleaned_periods.append(periods[i])\n",
    "                    except:\n",
    "                        cleaned_vals.append(np.nan)\n",
    "                        cleaned_periods.append(periods[i]) # Keep period even if value is NaN\n",
    "            return cleaned_vals, cleaned_periods\n",
    "    return None, None # Return None for both values and periods\n",
    "\n",
    "def safe_ratio(numerator, denominator):\n",
    "    if denominator is None or np.isnan(denominator) or denominator == 0:\n",
    "        return np.nan\n",
    "    if numerator is None or np.isnan(numerator):\n",
    "        return 0 # Treat missing numerator as 0 for ratio calculation\n",
    "    # Ensure both are numerical before division\n",
    "    if not isinstance(numerator, (int, float, np.number)) or not isinstance(denominator, (int, float, np.number)):\n",
    "         return np.nan # Or raise an error, depending on desired behavior for non-numeric inputs\n",
    "    return numerator / denominator\n",
    "\n",
    "def get_latest_fiscal_data(values, periods):\n",
    "    \"\"\"\n",
    "    Given a list of values and periods (most recent first),\n",
    "    returns the value and period for the latest complete fiscal year\n",
    "    and the previous fiscal year. Skips LTM data.\n",
    "    \"\"\"\n",
    "    if values is None or periods is None or len(values) < 2 or len(values) != len(periods):\n",
    "        return None, None, None, None # Need at least 2 values and matching periods\n",
    "\n",
    "    fiscal_data = [(v, p) for v, p in zip(values, periods) if 'LTM' not in str(p)]\n",
    "\n",
    "    if len(fiscal_data) < 2:\n",
    "        return None, None, None, None # Need at least 2 fiscal years\n",
    "\n",
    "    # fiscal_data is already sorted most recent first from extract_row\n",
    "    latest_fiscal_value, latest_fiscal_period = fiscal_data[0]\n",
    "    previous_fiscal_value, previous_fiscal_period = fiscal_data[1]\n",
    "\n",
    "    return latest_fiscal_value, latest_fiscal_period, previous_fiscal_value, previous_fiscal_period\n",
    "\n",
    "def get_last_two_periods_data(values, periods):\n",
    "    \"\"\"\n",
    "    Given a list of values and periods (most recent first),\n",
    "    returns the value and period for the last two available periods,\n",
    "    including LTM if present.\n",
    "    \"\"\"\n",
    "    if values is None or periods is None or len(values) < 2 or len(values) != len(periods):\n",
    "        return None, None, None, None # Need at least 2 values and matching periods\n",
    "\n",
    "    # values and periods are already sorted most recent first from extract_row\n",
    "    latest_value, latest_period = values[0], periods[0]\n",
    "    previous_value, previous_period = values[1], periods[1]\n",
    "\n",
    "    return latest_value, latest_period, previous_value, previous_period\n",
    "\n",
    "def extract_market_cap_from_overview(ticker):\n",
    "    \"\"\"\n",
    "    Attempts to extract Market Cap from the overview page and infer its scale.\n",
    "    Returns market cap value and scale factor (e.g., 1e6 for millions, 1e9 for billions).\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(ticker=ticker, statement=\"overview\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore nella richiesta per overview: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    # Use the user's provided logic to find Market Cap text and the next element\n",
    "    market_cap_text_element = soup.find(string=lambda text: text and \"Market Cap\" in text)\n",
    "\n",
    "    if market_cap_text_element:\n",
    "        # The value and scale are likely in the next sibling element\n",
    "        value_element = market_cap_text_element.find_next()\n",
    "        if value_element:\n",
    "            raw_value_text = value_element.text.strip()\n",
    "            print(f\"Raw Market Cap text found: '{raw_value_text}'\") # Debug print\n",
    "\n",
    "            # Improved logic to parse the value and scale\n",
    "            import re\n",
    "            # Regex to find a number (including commas and a potential decimal) followed by optional scale indicator\n",
    "            match = re.search(r'([\\d,]+\\.?\\d*)\\s*(Bil|Mil|Thou|billion|million|thousand)?', raw_value_text, re.IGNORECASE)\n",
    "\n",
    "            if match:\n",
    "                value_str = match.group(1).replace(',', '') # Remove commas before converting to float\n",
    "                scale_indicator = match.group(2)\n",
    "\n",
    "                try:\n",
    "                    value = float(value_str)\n",
    "                    scale_factor = 1.0 # Default scale (base units)\n",
    "\n",
    "                    if scale_indicator:\n",
    "                         if scale_indicator.lower() in ['bil', 'billion']:\n",
    "                             scale_factor = 1e9\n",
    "                             print(\"Market Cap scale inferred from overview: Billions\")\n",
    "                         elif scale_indicator.lower() in ['mil', 'million']:\n",
    "                             scale_factor = 1e6\n",
    "                             print(\"Market Cap scale inferred from overview: Millions\")\n",
    "                         elif scale_indicator.lower() in ['thou', 'thousand']:\n",
    "                             scale_factor = 1e3\n",
    "                             print(\"Market Cap scale inferred from overview: Thousands\")\n",
    "                         else:\n",
    "                              # If indicator is present but not recognized, assume millions as a fallback\n",
    "                              print(f\"Unrecognized scale indicator '{scale_indicator}' found in overview. Assuming millions.\")\n",
    "                              scale_factor = 1e6\n",
    "                    else:\n",
    "                         # If no scale indicator is found, try to infer from magnitude (less reliable)\n",
    "                         # Based on user feedback for this site, assume billions for large companies if no indicator\n",
    "                         if value > 1e9: # If the raw value is very large, it's likely in base units and needs scaling\n",
    "                              scale_factor = 1e9 # Assume financial data is in billions, so scale Market Cap to billions\n",
    "                              print(\"Market Cap scale inferred from magnitude (assuming billions).\")\n",
    "                         elif value > 1e6:\n",
    "                              scale_factor = 1e6 # Assume financial data is in millions\n",
    "                              print(\"Market Cap scale inferred from magnitude (assuming millions).\")\n",
    "                         else:\n",
    "                              scale_factor = 1.0\n",
    "                              print(\"Market Cap scale inferred from magnitude (assuming base units).\")\n",
    "\n",
    "                    return value, scale_factor\n",
    "\n",
    "                except ValueError:\n",
    "                    print(f\"Could not parse Market Cap value from overview text: {value_str}\")\n",
    "                    return None, None\n",
    "            else:\n",
    "                print(f\"Market Cap value and scale indicator not found in expected format in overview text: '{raw_value_text}'\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(\"Market Cap value element not found after 'Market Cap' text.\")\n",
    "            return None, None\n",
    "\n",
    "    print(\"'Market Cap' text not found on overview page.\")\n",
    "    return None, None\n",
    "\n",
    "# ==========================================\n",
    "# CALCOLO Z-SCORE, M-SCORE, F-SCORE\n",
    "# ==========================================\n",
    "def calculate_scores(ticker, years):\n",
    "    # Initialize scores and interpretations to default values\n",
    "    z_score = np.nan\n",
    "    z_interp = \"🔴 Dati insufficienti\"\n",
    "    m_score = np.nan\n",
    "    m_interp = \"🔴 Dati insufficienti\"\n",
    "    f_points = np.nan # Initialize as NaN, will be calculated later if data is sufficient\n",
    "    f_interp = \"🔴 Dati insufficienti\"\n",
    "    f_details = [] # Start with empty details, will be populated during calculation\n",
    "    overall = \"🔴 Dati incompleti per una valutazione affidabile\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # ESTRAZIONE\n",
    "    # -------------------------------\n",
    "    is_df = get_table_discounting(ticker, \"income-statement\")\n",
    "    bs_df = get_table_discounting(ticker, \"balance-sheet-statement\")\n",
    "    cf_df = get_table_discounting(ticker, \"cash-flow-statement\")\n",
    "\n",
    "    # Extract full data and periods (most recent first) - These should be extracted regardless of initial checks\n",
    "    revenue_full, rev_periods_full = extract_row(is_df, [\"Revenue\", \"Sales\"])\n",
    "    ni_full, ni_periods_full = extract_row(is_df, [\"Net Income\"])\n",
    "    gp_full, gp_periods_full = extract_row(is_df, [\"Gross Profit\"])\n",
    "    sga_full, sga_periods_full = extract_row(is_df, [\"Selling\", \"General\"])\n",
    "    dep_full, dep_periods_full = extract_row(is_df, [\"Depreciation\"])\n",
    "    receiv_full, receiv_periods_full = extract_row(bs_df, [\"Receivable\"])\n",
    "    ta_full, ta_periods_full = extract_row(bs_df, [\"Total Assets\"])\n",
    "    ca_full, ca_periods_full = extract_row(bs_df, [\"Current Assets\"])\n",
    "    ppe_full, ppe_periods_full = extract_row(bs_df, [\"Property, Plant\", \"PPE\"])\n",
    "    td_full, td_periods_full = extract_row(bs_df, [\"Total Liabilities\"]) # Corrected keyword to be more specific\n",
    "    cl_full, cl_periods_full = extract_row(bs_df, [\"Current Liabilities\"]) # Explicitly extract Current Liabilities\n",
    "    op_income_full, op_income_periods_full = extract_row(is_df, [\"Operating Income\"])\n",
    "    cfo_full, cfo_periods_full = extract_row(cf_df, [\"Cash Flow from Operations\", \"Operating Cash Flow\"])\n",
    "    equity_full, equity_periods_full = extract_row(bs_df, [\"Total Equity\", \"Total shareholders' equity\", \"Total stockholders' equity\"])\n",
    "    fcf_full, fcf_periods_full = extract_row(cf_df, [\"Free Cash Flow\", \"Free cash flow\", \"FreeCashFlow\", \"Operating Cash Flow\"])\n",
    "\n",
    "    # Extract specific data for Piotroski points 5 and 7 (as per user request)\n",
    "    # Point 5: Long-Term Debt and Capital Lease Obligations\n",
    "    ltd_full, ltd_periods_full = extract_row(bs_df, [\"Long-Term Debt\", \"Long Term Debt\"]) # Keywords for Long-Term Debt\n",
    "    clo_full, clo_periods_full = extract_row(bs_df, [\"Capital Lease Obligations\", \"Capital Lease Liability\"]) # Keywords for Capital Lease Obligations\n",
    "    # Point 7: Shares Outstanding - Extract from Income Statement based on user feedback\n",
    "    so_full, so_periods_full = extract_row(is_df, [\"Diluted Weighted Average Shares Outstanding\", \"Weighted Average Shares Outstanding\", \"Shares Outstanding\", \"Shares\", \"Common Stock Shares Outstanding\", \"Weighted Average Shares\", \"Common Stock Shares\"])\n",
    "\n",
    "    # --- Removed strict initial data check ---\n",
    "    # Instead, rely on individual index calculations to handle missing data.\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get latest available data (first element in the lists) for Z & M Scores (as per user request)\n",
    "    # -------------------------------\n",
    "    # Use the absolute latest data available (could be LTM)\n",
    "    latest_revenue = revenue_full[0] if revenue_full and len(revenue_full) > 0 else np.nan\n",
    "    latest_ni = ni_full[0] if ni_full and len(ni_full) > 0 else np.nan\n",
    "    latest_gp = gp_full[0] if gp_full and len(gp_full) > 0 else np.nan\n",
    "    latest_sga = sga_full[0] if sga_full and len(sga_full) > 0 else np.nan\n",
    "    latest_dep = dep_full[0] if dep_full and len(dep_full) > 0 else np.nan\n",
    "    latest_receiv = receiv_full[0] if receiv_full and len(receiv_full) > 0 else np.nan\n",
    "    latest_ta = ta_full[0] if ta_full and len(ta_full) > 0 else np.nan\n",
    "    latest_ca = ca_full[0] if ca_full and len(ca_full) > 0 else np.nan\n",
    "    latest_ppe = ppe_full[0] if ppe_full and len(ppe_full) > 0 else np.nan\n",
    "    latest_td = td_full[0] if td_full and len(td_full) > 0 else np.nan\n",
    "    latest_cl = cl_full[0] if cl_full and len(cl_full) > 0 else np.nan\n",
    "    latest_op_income = op_income_full[0] if op_income_full and len(op_income_full) > 0 else np.nan\n",
    "    latest_cfo = cfo_full[0] if cfo_full and len(cfo_full) > 0 else np.nan\n",
    "    latest_equity = equity_full[0] if equity_full and len(equity_full) > 0 else np.nan\n",
    "    latest_fcf = fcf_full[0] if fcf_full and len(fcf_full) > 0 else np.nan\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get data for the last two AVAILABLE periods for Beneish M-Score\n",
    "    # -------------------------------\n",
    "    # Use the last two available periods (could include LTM) for M-Score ratios\n",
    "    latest_receiv_m, latest_period_receiv_m, previous_receiv_m, previous_period_receiv_m = get_last_two_periods_data(receiv_full, receiv_periods_full)\n",
    "    latest_revenue_m, latest_period_rev_m, previous_revenue_m, previous_period_rev_m = get_last_two_periods_data(revenue_full, rev_periods_full)\n",
    "    latest_gp_m, latest_period_gp_m, previous_gp_m, previous_period_gp_m = get_last_two_periods_data(gp_full, gp_periods_full)\n",
    "    latest_ca_m, latest_period_ca_m, previous_ca_m, previous_period_ca_m = get_last_two_periods_data(ca_full, ca_periods_full)\n",
    "    latest_ppe_m, latest_period_ppe_m, previous_ppe_m, previous_period_ppe_m = get_last_two_periods_data(ppe_full, ppe_periods_full) # Corrected variable name previous_ppe_m\n",
    "    latest_ta_m, latest_period_ta_m, previous_ta_m, previous_period_ta_m = get_last_two_periods_data(ta_full, ta_periods_full)\n",
    "    latest_td_m, latest_period_td_m, previous_td_m, previous_period_td_m = get_last_two_periods_data(td_full, td_periods_full)\n",
    "    latest_equity_m, latest_period_equity_m, previous_equity_m, previous_period_equity_m = get_last_two_periods_data(equity_full, equity_periods_full)\n",
    "    latest_dep_m, latest_period_dep_m, previous_dep_m, previous_period_dep_m = get_last_two_periods_data(dep_full, dep_periods_full)\n",
    "    latest_sga_m, latest_period_sga_m, previous_sga_m, previous_period_sga_m = get_last_two_periods_data(sga_full, sga_periods_full)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get data for the last two AVAILABLE periods for Piotroski F-Score (as per user request)\n",
    "    # -------------------------------\n",
    "    # Now Piotroski will also use the last two available periods (could include LTM)\n",
    "    # Get data for all required Piotroski metrics for the last two periods\n",
    "    latest_ni_f, latest_period_ni_f, previous_ni_f, previous_period_ni_f = get_last_two_periods_data(ni_full, ni_periods_full)\n",
    "    latest_cfo_f, latest_period_cfo_f, previous_cfo_f, previous_period_cfo_f = get_last_two_periods_data(cfo_full, cfo_periods_full)\n",
    "    latest_ta_f, latest_period_ta_f, previous_ta_f, previous_period_ta_f = get_last_two_periods_data(ta_full, ta_periods_full)\n",
    "    latest_cl_f, latest_period_cl_f, previous_cl_f, previous_period_cl_f = get_last_two_periods_data(cl_full, cl_periods_full)\n",
    "    latest_equity_f, latest_period_equity_f, previous_equity_f, previous_period_equity_f = get_last_two_periods_data(equity_full, equity_periods_full)\n",
    "    latest_revenue_f, latest_period_rev_f, previous_revenue_f, previous_period_rev_f = get_last_two_periods_data(revenue_full, rev_periods_full)\n",
    "    latest_gp_f, latest_period_gp_f, previous_gp_f, previous_period_gp_f = get_last_two_periods_data(gp_full, gp_periods_full)\n",
    "    latest_td_f, latest_period_td_f, previous_td_f, previous_period_td_f = get_last_two_periods_data(td_full, td_periods_full)\n",
    "    latest_ca_f, latest_period_ca_f, previous_ca_f, previous_period_ca_f = get_last_two_periods_data(ca_full, ca_periods_full)\n",
    "    latest_ltd_f, latest_period_ltd_f, previous_ltd_f, previous_period_ltd_f = get_last_two_periods_data(ltd_full, ltd_periods_full)\n",
    "    latest_clo_f, latest_period_clo_f, previous_clo_f, previous_period_clo_f = get_last_two_periods_data(clo_full, clo_periods_full)\n",
    "    latest_so_f, latest_period_so_f, previous_so_f, previous_period_so_f = get_last_two_periods_data(so_full, so_periods_full) # Use so_full extracted from IS_df\n",
    "\n",
    "    # -------------------------------\n",
    "    # CALCOLO VARIABILI PER M-SCORE (using last two available periods)\n",
    "    # -------------------------------\n",
    "    # Use last two available periods for year-over-year ratios in M-Score\n",
    "    DSRI = safe_ratio(safe_ratio(latest_receiv_m, latest_revenue_m),\n",
    "                       safe_ratio(previous_receiv_m, previous_revenue_m))\n",
    "\n",
    "    GMI = safe_ratio(safe_ratio(previous_gp_m, previous_revenue_m),\n",
    "                       safe_ratio(latest_gp_m, latest_revenue_m))\n",
    "\n",
    "    # Ensure inputs to safe_ratio are numerical before the addition\n",
    "    aq_latest_m = 1 - safe_ratio((latest_ca_m if isinstance(latest_ca_m, (int, float, np.number)) else np.nan) + (latest_ppe_m if isinstance(latest_ppe_m, (int, float, np.number)) else np.nan), latest_ta_m)\n",
    "    aq_previous_m = 1 - safe_ratio((previous_ca_m if isinstance(previous_ca_m, (int, float, np.number)) else np.nan) + (previous_ppe_m if isinstance(previous_ppe_m, (int, float, np.number)) else np.nan), previous_ta_m)\n",
    "\n",
    "    AQI = safe_ratio(aq_latest_m, aq_previous_m)\n",
    "\n",
    "    SGI = safe_ratio(latest_revenue_m, previous_revenue_m)\n",
    "\n",
    "    # TATA uses latest available data (could be LTM), no previous period needed for the ratio itself\n",
    "    # Using latest_ni, latest_cfo, latest_ta which are from the absolute latest period\n",
    "    TATA = safe_ratio((latest_ni if isinstance(latest_ni, (int, float, np.number)) else np.nan) - (latest_cfo if isinstance(latest_cfo, (int, float, np.number)) else np.nan), latest_ta)\n",
    "\n",
    "    LVGI = safe_ratio(safe_ratio(latest_td_m, latest_equity_m),\n",
    "                       safe_ratio(previous_td_m, previous_equity_m))\n",
    "\n",
    "    # DEPI (Depreciation Index) - Ratio of depreciation rate in current year to previous year\n",
    "    # Depreciation rate = Depreciation / (PPE + Depreciation)\n",
    "    # Ensure inputs to safe_ratio are numerical before the addition\n",
    "    dep_rate_latest_m = safe_ratio(latest_dep_m, (latest_ppe_m if isinstance(latest_ppe_m, (int, float, np.number)) else np.nan) + (latest_dep_m if isinstance(latest_dep_m, (int, float, np.number)) else np.nan))\n",
    "    dep_rate_previous_m = safe_ratio(previous_dep_m, (previous_ppe_m if isinstance(previous_ppe_m, (int, float, np.number)) else np.nan) + (previous_dep_m if isinstance(previous_dep_m, (int, float, np.number)) else np.nan))\n",
    "    DEPI = safe_ratio(dep_rate_previous_m, dep_rate_latest_m) # Note: Formula in user's example seems to use previous/current\n",
    "\n",
    "    # SGAI (Sales, General, and Administrative Expenses Index) - Ratio of SGA to Sales in current year to previous year\n",
    "    # SGA to Sales ratio = SGA / Revenue\n",
    "    sga_sales_ratio_latest_m = safe_ratio(latest_sga_m, latest_revenue_m)\n",
    "    sga_sales_ratio_previous_m = safe_ratio(previous_sga_m, previous_revenue_m)\n",
    "    SGAI = safe_ratio(sga_sales_ratio_latest_m, sga_sales_ratio_previous_m)\n",
    "\n",
    "    # === BENEISH M-SCORE ===\n",
    "    # Calculate M-Score after calculating its components\n",
    "    # Use the 8-variable formula based on user's provided calculation\n",
    "    # M = -4.84 + 0.92 * DSRI + 0.528 * GMI + 0.404 * AQI + 0.892 * SGI + 0.115 * DEPI - 0.172 * SGAI + 4.679 * TATA - 0.327 * LVGI\n",
    "    m_score_components = {\n",
    "        'DSRI': DSRI,\n",
    "        'GMI': GMI,\n",
    "        'AQI': AQI,\n",
    "        'SGI': SGI,\n",
    "        'TATA': TATA,\n",
    "        'LVGI': LVGI,\n",
    "        'DEPI': DEPI,\n",
    "        'SGAI': SGAI\n",
    "    }\n",
    "\n",
    "    # Check if all required variables for the 8-variable M-Score are available (not NaN)\n",
    "    if any(np.isnan(list(m_score_components.values()))):\n",
    "        m_score = np.nan\n",
    "    else:\n",
    "         # 8-variable Beneish M-Score formula\n",
    "         m_score = (-4.84\n",
    "                    + 0.92 * m_score_components['DSRI']\n",
    "                    + 0.528 * m_score_components['GMI']\n",
    "                    + 0.404 * m_score_components['AQI']\n",
    "                    + 0.892 * m_score_components['SGI']\n",
    "                    + 0.115 * m_score_components['DEPI']\n",
    "                    - 0.172 * m_score_components['SGAI']\n",
    "                    + 4.679 * m_score_components['TATA']\n",
    "                    - 0.327 * m_score_components['LVGI'])\n",
    "\n",
    "    if np.isnan(m_score):\n",
    "        m_interp = \"🔴 Dati insufficienti\"\n",
    "    # Note: The typical cutoff for the 8-variable model is often -1.78\n",
    "    elif m_score < -1.78:\n",
    "        m_interp = \"💚 Bassa probabilità di manipolazione (secondo il modello a 8 variabili)\"\n",
    "    else:\n",
    "        m_interp = \"🔴 Possibile manipolazione contabile (secondo il modello a 8 variabili)\"\n",
    "\n",
    "    # === ALTMAN Z-SCORE ===\n",
    "    # Use latest available data for Altman Z-Score components (as per user request)\n",
    "    try:\n",
    "        total_assets_altman = latest_ta\n",
    "        total_liabilities_altman = latest_td\n",
    "        current_assets_altman = latest_ca\n",
    "        current_liabilities_altman = latest_cl\n",
    "        equity_altman = latest_equity\n",
    "        revenue_altman = latest_revenue\n",
    "        ni_altman = latest_ni\n",
    "        dep_altman = latest_dep\n",
    "        op_income_altman = op_income_full[0] if op_income_full and len(op_income_full) > 0 else np.nan # Use latest Op Income\n",
    "\n",
    "        # Handle cases where data might have NaNs or be insufficient for base Z-score components\n",
    "        if np.isnan(total_assets_altman) or total_assets_altman == 0 or \\\n",
    "           np.isnan(current_assets_altman) or np.isnan(current_liabilities_altman) or \\\n",
    "           np.isnan(revenue_altman) or np.isnan(ni_altman): # Added ni_altman check for RE and EBIT\n",
    "             z_score = np.nan\n",
    "             z_interp = \"🔴 Dati insufficienti\"\n",
    "             # Store error message for later printing\n",
    "             altman_error_message = \"Altman Z-Score Data (Latest Available): Insufficient base data for calculation.\"\n",
    "        else:\n",
    "            # Use Operating Income if available, otherwise approximate EBIT (using latest available data)\n",
    "            if op_income_altman is not None and not np.isnan(op_income_altman):\n",
    "                ebit_altman = op_income_altman\n",
    "            elif ni_altman is not None and not np.isnan(ni_altman) and dep_altman is not None and not np.isnan(dep_altman):\n",
    "                 ebit_altman = ni_altman + dep_altman\n",
    "            else:\n",
    "                 ebit_altman = np.nan # EBIT might be NaN if both Op Income and NI+Dep are missing\n",
    "\n",
    "            # Get Market Cap - Prioritize overview page\n",
    "            market_cap_altman_value = np.nan # Initialize as NaN\n",
    "            market_cap_scale_factor = np.nan # Initialize scale factor\n",
    "\n",
    "            overview_mc_value, overview_scale = extract_market_cap_from_overview(ticker)\n",
    "\n",
    "            if overview_mc_value is not None and overview_scale is not None:\n",
    "                 market_cap_altman_value = overview_mc_value\n",
    "                 market_cap_scale_factor = overview_scale # Use the scale inferred from overview\n",
    "                 print(f\"Market Cap value from overview: {market_cap_altman_value}, Scale Factor: {market_cap_scale_factor}\")\n",
    "\n",
    "                 # Calculate components using the latest available data point\n",
    "                 wc_ta = safe_ratio((current_assets_altman if isinstance(current_assets_altman, (int, float, np.number)) else np.nan) - (current_liabilities_altman if isinstance(current_liabilities_altman, (int, float, np.number)) else np.nan), total_assets_altman)\n",
    "                 # For Retained Earnings approximation, sum Net Income over the specified years (most recent first)\n",
    "                 # Use ni_full which contains all extracted Net Income values\n",
    "                 retained_earnings_altman_approx = np.nansum(ni_full[:years]) # Sum over the last 'years' extracted\n",
    "                 re_ta = safe_ratio(retained_earnings_altman_approx, total_assets_altman)\n",
    "\n",
    "                 ebit_ta = safe_ratio(ebit_altman, total_assets_altman)\n",
    "\n",
    "                 # Use Market Value of Equity (Market Cap) and Total Liabilities (latest available)\n",
    "                 # Ensure both are non-NaN before ratio calculation.\n",
    "                 # Scale Market Cap to the same scale as Total Liabilities (assuming millions based on previous output).\n",
    "                 assumed_financial_scale = 1e6 # Assuming financial data (like Total Liabilities) is in millions\n",
    "                 if not np.isnan(market_cap_altman_value) and not np.isnan(total_liabilities_altman) and total_liabilities_altman != 0 and not np.isnan(market_cap_scale_factor):\n",
    "                      # Convert Market Cap value from its extracted scale to the assumed financial data scale (millions)\n",
    "                      scaled_market_cap = market_cap_altman_value * (market_cap_scale_factor / assumed_financial_scale)\n",
    "                      mve_tl = safe_ratio(scaled_market_cap, total_liabilities_altman) # Total Liabilities assumed to be in millions\n",
    "                 else:\n",
    "                      mve_tl = np.nan # X4 will be NaN if Market Cap or its scale is missing\n",
    "\n",
    "                 s_ta = safe_ratio(revenue_altman, total_assets_altman)\n",
    "\n",
    "                 # Calculate Z-Score only if all components are available\n",
    "                 if not any(np.isnan([wc_ta, re_ta, ebit_ta, mve_tl, s_ta])):\n",
    "                      z_score = 1.2*wc_ta + 1.4*re_ta + 3.3*ebit_ta + 0.6*mve_tl + 1.0*s_ta\n",
    "                      if z_score > 2.99: z_interp = \"💚 Solida (basso rischio di fallimento)\"\n",
    "                      elif z_score >= 1.81: z_interp = \"🟡 Zona grigia (moderato rischio)\"\n",
    "                      else: z_interp = \"🔴 Rischio elevato di insolvenza\"\n",
    "                 else:\n",
    "                      z_score = np.nan\n",
    "                      z_interp = \"🔴 Dati insufficienti\"\n",
    "\n",
    "                 # Store Altman Z-Score Components Details for later printing\n",
    "                 altman_component_prints = [\n",
    "                     f\"WC/TA (X1): {wc_ta:.4f}\",\n",
    "                     f\"RE/TA (X2): {re_ta:.4f}\",\n",
    "                     f\"EBIT/TA (X3): {ebit_ta:.4f}\",\n",
    "                     f\"MVE/TL (X4): {mve_tl:.4f}\" if not np.isnan(mve_tl) else \"MVE/TL (X4): N/A (Market Cap Missing/Scale Unclear)\",\n",
    "                     f\"S/TA (X5): {s_ta:.4f}\"\n",
    "                 ]\n",
    "                 altman_error_message = None\n",
    "\n",
    "            else:\n",
    "                 print(\"⚠️ Market Cap not found on overview page with clear scale. Cannot calculate X4 accurately.\")\n",
    "                 # If overview fails, set Z-score related variables to NaN/default\n",
    "                 mve_tl = np.nan\n",
    "                 z_score = np.nan\n",
    "                 z_interp = \"🔴 Dati insufficienti\"\n",
    "                 # Store Altman Z-Score Components Details for later printing (with N/A for X4)\n",
    "                 wc_ta = safe_ratio((current_assets_altman if isinstance(current_assets_altman, (int, float, np.number)) else np.nan) - (current_liabilities_altman if isinstance(current_liabilities_altman, (int, float, np.number)) else np.nan), total_assets_altman)\n",
    "                 retained_earnings_altman_approx = np.nansum(ni_full[:years]) # Sum over the last 'years' extracted\n",
    "                 re_ta = safe_ratio(retained_earnings_altman_approx, total_assets_altman)\n",
    "                 ebit_ta = safe_ratio(ebit_altman, total_assets_altman)\n",
    "                 s_ta = safe_ratio(revenue_altman, total_assets_altman)\n",
    "                 altman_component_prints = [\n",
    "                     f\"WC/TA (X1): {wc_ta:.4f}\",\n",
    "                     f\"RE/TA (X2): {re_ta:.4f}\",\n",
    "                     f\"EBIT/TA (X3): {ebit_ta:.4f}\",\n",
    "                     f\"MVE/TL (X4): N/A (Market Cap Missing/Scale Unclear)\",\n",
    "                     f\"S/TA (X5): {s_ta:.4f}\"\n",
    "                 ]\n",
    "                 altman_error_message = \"Altman Z-Score Data (Latest Available): Insufficient Market Cap data with reliable scale for X4 calculation.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore calcolo Z-Score: {e}\")\n",
    "        z_score = np.nan\n",
    "        z_interp = \"🔴 Dati insufficienti\"\n",
    "        altman_component_prints = [] # Clear components on general error\n",
    "        altman_error_message = f\"Errore calcolo Z-Score: {e}\"\n",
    "\n",
    "    # === PIOTROSKI F-SCORE (using last two available periods) ===\n",
    "    f_points = 0 # Initialize points to 0, will add points based on available data\n",
    "    f_details = [] # Reset f_details\n",
    "\n",
    "    try:\n",
    "        # Profitability criteria (4 points)\n",
    "        # 1. Positive Net Income (Latest Period)\n",
    "        if latest_ni_f is not None and not np.isnan(latest_ni_f) and latest_ni_f > 0:\n",
    "            f_points += 1\n",
    "            f_details.append(f\"1. Net Income ({latest_ni_f:,.0f}) > 0 (+1 point) [{latest_period_ni_f}]\") # Added period\n",
    "        else:\n",
    "            f_details.append(f\"1. Net Income ({latest_ni_f if latest_ni_f is not None and not np.isnan(latest_ni_f) else 'N/A'} @{latest_period_ni_f}) <= 0 or data missing (+0 points)\") # Added period\n",
    "\n",
    "        # 2. Positive Cash Flow from Operations (Latest Period)\n",
    "        if latest_cfo_f is not None and not np.isnan(latest_cfo_f) and latest_cfo_f > 0:\n",
    "            f_points += 1\n",
    "            f_details.append(f\"2. CFO ({latest_cfo_f:,.0f}) > 0 (+1 point) [{latest_period_cfo_f}]\") # Added period\n",
    "        else:\n",
    "             f_details.append(f\"2. CFO ({latest_cfo_f if latest_cfo_f is not None and not np.isnan(latest_cfo_f) else 'N/A'} @{latest_period_cfo_f}) <= 0 or data missing (+0 points)\") # Added period\n",
    "\n",
    "        # 3. Return on Assets (ROA) improvement (Latest Period vs Previous Period)\n",
    "        roa_curr = safe_ratio(latest_ni_f, latest_ta_f)\n",
    "        roa_prev = safe_ratio(previous_ni_f, previous_ta_f)\n",
    "        if not np.isnan(roa_curr) and not np.isnan(roa_prev) and roa_curr > roa_prev:\n",
    "             f_points += 1\n",
    "             f_details.append(f\"3. ROA ({roa_curr:.4f} @{latest_period_ni_f}/{latest_period_ta_f}) > Previous ROA ({roa_prev:.4f} @{previous_period_ni_f}/{previous_period_ta_f}) (+1 point)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"3. ROA ({roa_curr:.4f}) <= Previous ROA ({roa_prev:.4f}) or data missing (+0 points) [Latest @{latest_period_ni_f}/{latest_period_ta_f}, Previous @{previous_period_ni_f}/{previous_period_ta_f}]\") # Added periods\n",
    "\n",
    "        # 4. Cash Flow from Operations (CFO) > Net Income (Latest Period)\n",
    "        if not np.isnan(latest_cfo_f) and not np.isnan(latest_ni_f) and latest_cfo_f > latest_ni_f:\n",
    "             f_points += 1\n",
    "             f_details.append(f\"4. CFO ({latest_cfo_f:,.0f}) > Net Income ({latest_ni_f:,.0f}) (+1 point) [Both @{latest_period_cfo_f}/{latest_period_ni_f}]\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"4. CFO ({latest_cfo_f:,.0f}) <= Net Income ({latest_ni_f:,.0f}) or data missing (+0 points) [Both @{latest_period_cfo_f}/{latest_period_ni_f}]\") # Added periods\n",
    "\n",
    "        # Leverage, Liquidity and Source of Funds criteria (3 points)\n",
    "        # 5. Lower Long-Term Debt + Capital Lease Obligations in the current year compared to the previous year (Latest Period vs Previous Period)\n",
    "        # Using sum of LTD and CLO\n",
    "        latest_total_long_term_debt = (latest_ltd_f if latest_ltd_f is not None and not np.isnan(latest_ltd_f) else 0) + \\\n",
    "                                      (latest_clo_f if latest_clo_f is not None and not np.isnan(latest_clo_f) else 0)\n",
    "        previous_total_long_term_debt = (previous_ltd_f if previous_ltd_f is not None and not np.isnan(previous_ltd_f) else 0) + \\\n",
    "                                        (previous_clo_f if previous_clo_f is not None and not np.isnan(previous_clo_f) else 0)\n",
    "        # Check if data for comparison exists for at least one component in both periods\n",
    "        if (latest_ltd_f is not None and not np.isnan(latest_ltd_f)) or (latest_clo_f is not None and not np.isnan(latest_clo_f)) or \\\n",
    "           (previous_ltd_f is not None and not np.isnan(previous_ltd_f)) or (previous_clo_f is not None and not np.isnan(previous_clo_f)):\n",
    "             # Only compare if we have data for at least one component in both periods\n",
    "             if latest_total_long_term_debt < previous_total_long_term_debt:\n",
    "                  f_points += 1\n",
    "                  f_details.append(f\"5. Long-Term Debt + CLO ({latest_total_long_term_debt:,.0f} @{latest_period_ltd_f}/{latest_period_clo_f}) < Previous ({previous_total_long_term_debt:,.0f} @{previous_period_ltd_f}/{previous_period_clo_f}) (+1 point)\") # Added periods\n",
    "             else:\n",
    "                  f_details.append(f\"5. Long-Term Debt + CLO ({latest_total_long_term_debt:,.0f} @{latest_period_ltd_f}/{latest_period_clo_f}) >= Previous ({previous_total_long_term_debt:,.0f} @{previous_period_ltd_f}/{previous_period_clo_f}) (+0 points)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"5. Long-Term Debt + CLO data insufficient for comparison (+0 points) [Latest @{latest_period_ltd_f}/{latest_period_clo_f}, Previous @{previous_period_ltd_f}/{previous_period_clo_f}]\") # Added periods\n",
    "\n",
    "        # 6. Higher Current Ratio in the current year compared to the previous year (Latest Period vs Previous Period)\n",
    "        cr_curr = safe_ratio(latest_ca_f, latest_cl_f)\n",
    "        cr_prev = safe_ratio(previous_ca_f, previous_cl_f)\n",
    "        if not np.isnan(cr_curr) and not np.isnan(cr_prev) and cr_curr > cr_prev:\n",
    "             f_points += 1\n",
    "             f_details.append(f\"6. Current Ratio ({cr_curr:.4f} @{latest_period_ca_f}/{latest_period_cl_f}) > Previous Current Ratio ({cr_prev:.4f} @{previous_period_ca_f}/{previous_period_cl_f}) (+1 point)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"6. Current Ratio ({cr_curr:.4f}) <= Previous Current Ratio ({cr_prev:.4f}) or data missing (+0 points) [Latest @{latest_period_ca_f}/{latest_period_cl_f}, Previous @{previous_period_ca_f}/{previous_period_cl_f}]\") # Added periods\n",
    "\n",
    "        # 7. No new shares issued in the last year (signified by stable or decreasing shares outstanding) (Latest Period vs Previous Period)\n",
    "        # Comparing Shares Outstanding directly\n",
    "        if latest_so_f is not None and not np.isnan(latest_so_f) and previous_so_f is not None and not np.isnan(previous_so_f):\n",
    "             if latest_so_f <= previous_so_f: # Score 1 if shares outstanding is less than or equal to previous\n",
    "                  f_points += 1\n",
    "                  f_details.append(f\"7. Shares Outstanding ({latest_so_f:,.0f} @{latest_period_so_f}) <= Previous ({previous_so_f:,.0f} @{previous_period_so_f}) (+1 point)\") # Added periods\n",
    "             else:\n",
    "                  f_details.append(f\"7. Shares Outstanding ({latest_so_f:,.0f} @{latest_period_so_f}) > Previous ({previous_so_f:,.0f} @{previous_period_so_f}) (+0 points)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"7. Shares Outstanding data insufficient for comparison (+0 points) [Latest @{latest_period_so_f}, Previous @{previous_period_so_f}]\") # Added periods\n",
    "\n",
    "        # Operating Efficiency criteria (2 points) - Changed to 2 points as point 4 moved to Profitability\n",
    "        # 8. Higher Gross Margin in the current year compared to the previous year (Latest Period vs Previous Period)\n",
    "        gm_curr = safe_ratio(latest_gp_f, latest_revenue_f)\n",
    "        gm_prev = safe_ratio(previous_gp_f, previous_revenue_f)\n",
    "        if not np.isnan(gm_curr) and not np.isnan(gm_prev) and gm_curr > gm_prev:\n",
    "             f_points += 1\n",
    "             f_details.append(f\"8. Gross Margin ({gm_curr:.4f} @{latest_period_gp_f}/{latest_period_rev_f}) > Previous Gross Margin ({gm_prev:.4f} @{previous_period_gp_f}/{previous_period_rev_f}) (+1 point)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"8. Gross Margin ({gm_curr:.4f}) <= Previous Gross Margin ({gm_prev:.4f}) or data missing (+0 points) [Latest @{latest_period_gp_f}/{latest_period_rev_f}, Previous @{previous_period_gp_f}/{previous_period_rev_f}]\") # Added periods\n",
    "\n",
    "        # 9. Higher Asset Turnover Ratio in the current year compared to the previous year (Latest Period vs Previous Period)\n",
    "        # Note: Asset Turnover = Revenue / Total Assets\n",
    "        at_curr = safe_ratio(latest_revenue_f, latest_ta_f)\n",
    "        at_prev = safe_ratio(previous_revenue_f, previous_ta_f)\n",
    "        if not np.isnan(at_curr) and not np.isnan(at_prev) and at_curr > at_prev:\n",
    "             f_points += 1\n",
    "             f_details.append(f\"9. Asset Turnover ({at_curr:.4f} @{latest_period_rev_f}/{latest_period_ta_f}) > Previous Asset Turnover ({at_prev:.4f} @{previous_period_rev_f}/{previous_period_ta_f}) (+1 point)\") # Added periods\n",
    "        else:\n",
    "             f_details.append(f\"9. Asset Turnover ({at_curr:.4f}) <= Previous Asset Turnover ({at_prev:.4f}) or data missing (+0 points) [Latest @{latest_period_rev_f}/{latest_period_ta_f}, Previous @{previous_period_rev_f}/{previous_period_ta_f}]\") # Added periods\n",
    "\n",
    "        # Set interpretation based on calculated points.\n",
    "        # Check if at least some key data was available to attempt calculation\n",
    "        core_data_for_fscore_available = (latest_ni_f is not None and not np.isnan(latest_ni_f) and previous_ni_f is not None and not np.isnan(previous_ni_f)) or \\\n",
    "                                       (latest_cfo_f is not None and not np.isnan(latest_cfo_f) and previous_cfo_f is not None and not np.isnan(previous_cfo_f)) or \\\n",
    "                                       (latest_ta_f is not None and not np.isnan(latest_ta_f) and previous_ta_f is not None and not np.isnan(previous_ta_f)) or \\\n",
    "                                       (latest_cl_f is not None and not np.isnan(latest_cl_f) and previous_cl_f is not None and not np.isnan(previous_cl_f)) or \\\n",
    "                                       (latest_equity_f is not None and not np.isnan(latest_equity_f) and previous_equity_f is not None and not np.isnan(previous_equity_f)) or \\\n",
    "                                       (latest_revenue_f is not None and not np.isnan(latest_revenue_f) and previous_revenue_f is not None and not np.isnan(previous_revenue_f)) or \\\n",
    "                                       (latest_gp_f is not None and not np.isnan(latest_gp_f) and previous_gp_f is not None and not np.isnan(previous_gp_f)) or \\\n",
    "                                       (latest_td_f is not None and not np.isnan(latest_td_f) and previous_td_f is not None and not np.isnan(previous_td_f)) or \\\n",
    "                                       (latest_ca_f is not None and not np.isnan(latest_ca_f) and previous_ca_f is not None and not np.isnan(previous_ca_f)) or \\\n",
    "                                       (latest_ltd_f is not None and not np.isnan(latest_ltd_f) and previous_ltd_f is not None and not np.isnan(previous_ltd_f)) or \\\n",
    "                                       (latest_clo_f is not None and not np.isnan(latest_clo_f) and previous_clo_f is not None and not np.isnan(previous_clo_f)) or \\\n",
    "                                       (latest_so_f is not None and not np.isnan(latest_so_f) and previous_so_f is not None and not np.isnan(previous_so_f)) # Check all required metrics for last two periods\n",
    "\n",
    "        if not core_data_for_fscore_available:\n",
    "             f_interp = \"🔴 Dati insufficienti per calcolare Punteggio F-Score\" # Specific message if fundamental data is missing\n",
    "             f_points = np.nan # Set to NaN if fundamental data is missing\n",
    "             # f_details already contains specific missing data points from individual checks\n",
    "        # elif f_details and all(\"data insufficient\" in detail for detail in f_details):\n",
    "             # f_interp = \"🔴 Dati insufficienti per calcolare Punteggio F-Score\" # More specific message if all points missed due to data\n",
    "             # f_points = np.nan # Set to NaN if all points missed due to data\n",
    "        elif f_points >= 8:\n",
    "            f_interp = \"💚 Molto solida (ottima efficienza)\"\n",
    "        elif f_points >= 5:\n",
    "            f_interp = \"🟡 Solida ma migliorabile\"\n",
    "        else:\n",
    "            f_interp = \"🔴 Debole (rischi elevati)\"\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"Errore calcolo F-Score: {e}\")\n",
    "         f_points = np.nan # Set to NaN on general error during calculation\n",
    "         f_interp = \"🔴 Dati insufficienti\"\n",
    "         f_details = [f\"Error during F-Score calculation: {e}\"] # Update details with error\n",
    "\n",
    "    # --- Debugging: Print data fetched for Piotroski ---\n",
    "    print(\"\\n--- Debugging Piotroski Data Extraction (Last Two Periods) ---\")\n",
    "    print(f\"Net Income (NI): Latest={latest_ni_f}, Period={latest_period_ni_f} | Previous={previous_ni_f}, Period={previous_period_ni_f}\")\n",
    "    print(f\"CFO: Latest={latest_cfo_f}, Period={latest_period_cfo_f} | Previous={previous_cfo_f}, Period={previous_period_cfo_f}\")\n",
    "    print(f\"Total Assets (TA): Latest={latest_ta_f}, Period={latest_period_ta_f} | Previous={previous_ta_f}, Period={previous_period_ta_f}\")\n",
    "    print(f\"Current Liabilities (CL): Latest={latest_cl_f}, Period={latest_period_cl_f} | Previous={previous_cl_f}, Period={previous_period_cl_f}\")\n",
    "    print(f\"Equity: Latest={latest_equity_f}, Period={latest_period_equity_f} | Previous={previous_equity_f}, Period={previous_period_equity_f}\")\n",
    "    print(f\"Revenue: Latest={latest_revenue_f}, Period={latest_period_rev_f} | Previous={previous_revenue_f}, Period={previous_period_rev_f}\")\n",
    "    print(f\"Gross Profit (GP): Latest={latest_gp_f}, Period={latest_period_gp_f} | Previous={previous_gp_f}, Period={previous_period_gp_f}\")\n",
    "    print(f\"Total Liabilities (TD): Latest={latest_td_f}, Period={latest_period_td_f} | Previous={previous_td_f}, Period={previous_period_td_f}\")\n",
    "    print(f\"Current Assets (CA): Latest={latest_ca_f}, Period={latest_period_ca_f} | Previous={previous_ca_f}, Period={previous_period_ca_f}\")\n",
    "    print(f\"Long-Term Debt (LTD): Latest={latest_ltd_f}, Period={latest_period_ltd_f} | Previous={previous_ltd_f}, Period={previous_period_ltd_f}\")\n",
    "    print(f\"Capital Lease Obligations (CLO): Latest={latest_clo_f}, Period={latest_period_clo_f} | Previous={previous_clo_f}, Period={previous_period_clo_f}\")\n",
    "    print(f\"Shares Outstanding (SO): Latest={latest_so_f}, Period={latest_period_so_f} | Previous={previous_so_f}, Period={previous_period_so_f}\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    # --- End Debugging Prints ---\n",
    "\n",
    "    # Print Altman Z-Score details if available\n",
    "    # Check if Altman components were calculated or an error occurred in that block\n",
    "    if 'altman_component_prints' in locals() or ('altman_error_message' in locals() and altman_error_message is not None):\n",
    "        print(\"\\n--- Altman Z-Score Components Details ---\")\n",
    "        if 'altman_error_message' in locals() and altman_error_message:\n",
    "             print(altman_error_message)\n",
    "        elif 'altman_component_prints' in locals() and altman_component_prints:\n",
    "             for comp in altman_component_prints:\n",
    "                 print(comp)\n",
    "        else:\n",
    "            # Should not happen if calculation was attempted, but as a fallback\n",
    "            print(\"Altman Z-Score component details not available.\")\n",
    "        print(\"---------------------------------------------------------\")\n",
    "\n",
    "    # Print Beneish M-Score details if available\n",
    "    # Check if M-Score components were calculated (even if m_score is NaN)\n",
    "    if any(comp in m_score_components for comp in ['DSRI', 'GMI', 'AQI', 'SGI', 'TATA', 'LVGI', 'DEPI', 'SGAI']):\n",
    "        print(\"\\n--- Beneish M-Score Components Details ---\")\n",
    "        # Print details for each component, including underlying values for ratios (using the M-Score specific data)\n",
    "        print(f\"DSRI (Days Sales in Receivables Index): {m_score_components.get('DSRI', np.nan):.4f}\")\n",
    "        print(f\"  Latest Period ({latest_period_receiv_m}): Receivables: {latest_receiv_m:,.0f}, Revenue: {latest_revenue_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_receiv_m}): Receivables: {previous_receiv_m:,.0f}, Revenue: {previous_revenue_m:,.0f}\")\n",
    "\n",
    "        print(f\"GMI (Gross Margin Index): {m_score_components.get('GMI', np.nan):.4f}\")\n",
    "        print(f\"  Latest Period ({latest_period_gp_m}): Gross Profit: {latest_gp_m:,.0f}, Revenue: {latest_revenue_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_gp_m}): Gross Profit: {previous_gp_m:,.0f}, Revenue: {previous_revenue_m:,.0f}\")\n",
    "\n",
    "        print(f\"AQI (Asset Quality Index): {AQI:.4f}\") # Use AQI variable directly\n",
    "        print(f\"  Latest Period ({latest_period_ca_m}): CA: {latest_ca_m:,.0f}, PPE: {latest_ppe_m:,.0f}, TA: {latest_ta_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_ca_m}): CA: {previous_ca_m:,.0f}, PPE: {previous_ppe_m:,.0f}, TA: {previous_ta_m:,.0f}\")\n",
    "\n",
    "        print(f\"SGI (Sales Growth Index): {m_score_components.get('SGI', np.nan):.4f}\")\n",
    "        print(f\"  Latest Period ({latest_period_rev_m}): Revenue: {latest_revenue_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_rev_m}): Revenue: {previous_revenue_m:,.0f}\")\n",
    "\n",
    "        print(f\"TATA (Total Accruals to Total Assets): {m_score_components.get('TATA', np.nan):.4f}\")\n",
    "        print(f\"  Latest Net Income: {latest_ni:,.0f}, Latest CFO: {latest_cfo:,.0f}, Latest Total Assets: {latest_ta:,.0f}\")\n",
    "\n",
    "        print(f\"LVGI (Leverage Index): {m_score_components.get('LVGI', np.nan):.4f}\") # Corrected format specifier\n",
    "        print(f\"  Latest Period ({latest_period_td_m}): Total Liabilities: {latest_td_m:,.0f}, Equity: {latest_equity_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_td_m}): Total Liabilities: {previous_td_m:,.0f}, Equity: {previous_equity_m:,.0f}\")\n",
    "\n",
    "        print(f\"DEPI (Depreciation Index): {m_score_components.get('DEPI', np.nan):.4f}\")\n",
    "        print(f\"  Latest Period ({latest_period_dep_m}): Depreciation: {latest_dep_m:,.0f}, PPE: {latest_ppe_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_dep_m}): Depreciation: {previous_dep_m:,.0f}, PPE: {previous_ppe_m:,.0f}\")\n",
    "\n",
    "        print(f\"SGAI (SGA Index): {m_score_components.get('SGAI', np.nan):.4f}\")\n",
    "        print(f\"  Latest Period ({latest_period_sga_m}): SGA: {latest_sga_m:,.0f}, Revenue: {latest_revenue_m:,.0f}\")\n",
    "        print(f\"  Previous Period ({previous_period_sga_m}): SGA: {previous_sga_m:,.0f}, Revenue: {previous_revenue_m:,.0f}\")\n",
    "\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "    # Print Piotroski F-Score details\n",
    "    print(\"\\nPiotroski F-Score Details:\")\n",
    "    for detail in f_details:\n",
    "        print(f\"- {detail}\")\n",
    "\n",
    "    # Print Summary Scores and Combined Interpretation at the very end\n",
    "    print(f\"\\n📊 Analisi di solidità per: {ticker}\") # Moved this line here\n",
    "    print(\"\\n--- Riepilogo Punteggi ---\")\n",
    "    print(f\"Altman Z-Score: {z_score:.2f} → {z_interp}\")\n",
    "    print(f\"Beneish M-Score: {m_score:.2f} → {m_interp}\")\n",
    "    print(f\"Piotroski F-Score: {f_points}/9 → {f_interp}\") # f_points might be NaN or a number\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    # === INTERPRETAZIONE COMBINATA ===\n",
    "    # Check if ALL scores have a valid, non-NaN value before providing a combined interpretation\n",
    "    if not np.isnan(z_score) and not np.isnan(m_score) and (f_points is not None and not np.isnan(f_points)): # Added check for f_points\n",
    "         # Use the 8-variable cutoff for M-Score in combined interpretation\n",
    "         if z_score > 2.99 and m_score < -1.78 and f_points >= 8:\n",
    "             overall = \"💚 Eccellente solidità e bilanci affidabili\"\n",
    "         elif z_score >= 1.81 and m_score < -1.78 and f_points >= 5:\n",
    "             overall = \"🟡 Solida ma da monitorare\"\n",
    "         else:\n",
    "             overall = \"🔴 Rischio elevato o possibili manipolazioni\"\n",
    "    else:\n",
    "         overall = \"🔴 Dati incompleti per una valutazione affidabile\" # Default if any score is NaN\n",
    "\n",
    "    print(f\"\\n🧠 Interpretazione combinata: {overall}\")\n",
    "\n",
    "# ==========================================\n",
    "# ESECUZIONE COMPLETA\n",
    "# ==========================================\n",
    "# Make sure TICKER and YEARS are defined (e.g., from the first cell)\n",
    "if 'TICKER' in globals() and 'YEARS' in globals():\n",
    "    calculate_scores(TICKER, YEARS)\n",
    "else:\n",
    "    print(\"⚠️ TICKER and/o r YEARS variables are not defined. Please run the first cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
