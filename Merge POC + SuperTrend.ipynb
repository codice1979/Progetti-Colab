{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CODICE 3 -  Merge POC + SuperTrend multiperiodo\n",
    "# ============================================\n",
    " \n",
    "import subprocess\n",
    "import sys\n",
    " \n",
    "# Funzione per installare i pacchetti\n",
    "def install_packages():\n",
    "    packages = ['yfinance', 'pandas', 'numpy', 'TA-Lib']\n",
    "    for package in packages:\n",
    "        try:\n",
    "            # Suppress output for pip install\n",
    "            with open(os.devnull, 'w') as f:\n",
    "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package], stdout=f, stderr=f)\n",
    "            print(f\"Installato {package} con successo\")\n",
    "        except:\n",
    "            print(f\"Errore nell'installazione di {package}\")\n",
    " \n",
    "# Installa i pacchetti necessari\n",
    "install_packages()\n",
    " \n",
    "# Importa le librerie\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import talib as ta\n",
    "    from datetime import datetime, timedelta\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    from google.colab import drive\n",
    "    import os\n",
    "    import contextlib\n",
    "except ImportError as e:\n",
    "    print(f\"Errore nell'importazione delle librerie: {e}\")\n",
    "    # Non uscire qui, permetti all'utente di vedere l'errore e risolverlo\n",
    "    # sys.exit(1)\n",
    " \n",
    " \n",
    "# === 1. Monta Drive e carica file ===\n",
    "# Suppress output for drive mount\n",
    "with open(os.devnull, 'w') as f:\n",
    "  with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "    # Aggiunto controllo per evitare di montare se già montato\n",
    "    if not os.path.exists('/content/drive'):\n",
    "      drive.mount('/content/drive')\n",
    "    else:\n",
    "      print(\"Google Drive già montato.\")\n",
    " \n",
    " \n",
    "week_number = datetime.now().isocalendar()[1]\n",
    "# Assicurati che 'poc_period' sia definito e corretto, usa un valore predefinito se necessario\n",
    "# Potresti voler recuperare 'poc_period' dalla cella precedente se non è globale\n",
    "try:\n",
    "  # Tenta di recuperare poc_period dalla cella precedente o usa un default\n",
    "  if 'poc_period' not in globals():\n",
    "      poc_period = '5y' # Default value if not found\n",
    " \n",
    "  poc_folder = '/content/drive/MyDrive/POC'\n",
    "  # Assicurati che il percorso del file corrisponda esattamente a quello di salvataggio\n",
    "  poc_file_path = os.path.join(poc_folder, f'POC{poc_period}_week_{week_number}.xlsx')\n",
    " \n",
    "  # Suppress output when loading the Excel file\n",
    "  with open(os.devnull, 'w') as f:\n",
    "    with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "      df_poc = pd.read_excel(poc_file_path)\n",
    " \n",
    "  print(\"File POC caricato con successo.\")\n",
    " \n",
    "except FileNotFoundError:\n",
    "    print(f\"Errore: File POC non trovato in {poc_file_path}.\")\n",
    "    print(\"Assicurati che la cella precedente sia stata eseguita correttamente e che il file esista.\")\n",
    "    # Non uscire qui, permetti al codice di continuare (anche se con un dataframe vuoto)\n",
    "    df_poc = pd.DataFrame() # Crea un dataframe vuoto per evitare errori successivi\n",
    "except Exception as e:\n",
    "    print(f\"Errore caricamento file POC: {e}\")\n",
    "    # Non uscire qui\n",
    "    df_poc = pd.DataFrame() # Crea un dataframe vuoto per evitare errori successivi\n",
    " \n",
    " \n",
    "# Procedi solo se il dataframe POC non è vuoto\n",
    "if not df_poc.empty:\n",
    " \n",
    "  # === 2. Funzioni di supporto per SuperTrend TradingView ===\n",
    "  def calculate_supertrend(high, low, close, atr_period, multiplier):\n",
    "      \"\"\"Calcola il Supertrend\"\"\"\n",
    " \n",
    "      # Ensure inputs are numpy arrays\n",
    "      high = np.asarray(high)\n",
    "      low = np.asarray(low)\n",
    "      close = np.asarray(close)\n",
    " \n",
    "      if len(high) < atr_period or len(low) < atr_period or len(close) < atr_period or atr_period <= 0:\n",
    "          # print(\"Dati insufficienti per calcolare Supertrend.\") # Opzionale: stampa un messaggio\n",
    "          return np.full_like(close, np.nan), np.full_like(close, np.nan)\n",
    " \n",
    "      # Calcolo ATR\n",
    "      atr = ta.ATR(high, low, close, timeperiod=atr_period)\n",
    " \n",
    "      # Calcolo delle bande\n",
    "      upperband = (high + low) / 2 + (multiplier * atr)\n",
    "      lowerband = (high + low) / 2 - (multiplier * atr)\n",
    " \n",
    "      # Inizializza Supertrend\n",
    "      supertrend = np.full_like(close, np.nan)\n",
    "      direction = np.full_like(close, np.nan)\n",
    " \n",
    "      # Find the first valid index after ATR calculation\n",
    "      first_valid_atr_idx = np.where(~np.isnan(atr))[0][0] if np.any(~np.isnan(atr)) else len(close)\n",
    " \n",
    "      if first_valid_atr_idx >= len(close):\n",
    "          # print(\"ATR non calcolabile per periodo specificato.\") # Opzionale: stampa un messaggio\n",
    "          return np.full_like(close, np.nan), np.full_like(close, np.nan)\n",
    " \n",
    "      # Initialize first valid Supertrend value\n",
    "      supertrend[first_valid_atr_idx] = upperband[first_valid_atr_idx]\n",
    "      direction[first_valid_atr_idx] = 1\n",
    " \n",
    " \n",
    "      # Calcola Supertrend\n",
    "      for i in range(first_valid_atr_idx + 1, len(close)):\n",
    "          # Use previous valid supertrend value if the current one is nan (can happen with short data)\n",
    "          prev_supertrend = supertrend[i-1] if not np.isnan(supertrend[i-1]) else (upperband[i-1] + lowerband[i-1]) / 2 # Fallback if prev is nan\n",
    " \n",
    "          if close[i] > prev_supertrend:\n",
    "              direction[i] = 1\n",
    "          else:\n",
    "              direction[i] = -1\n",
    " \n",
    "          if direction[i] == 1:\n",
    "              if lowerband[i] > prev_supertrend:\n",
    "                  supertrend[i] = lowerband[i]\n",
    "              else:\n",
    "                  supertrend[i] = prev_supertrend\n",
    "          else:\n",
    "              if upperband[i] < prev_supertrend:\n",
    "                  supertrend[i] = upperband[i]\n",
    "              else:\n",
    "                  supertrend[i] = prev_supertrend\n",
    " \n",
    "      # Backfill NaNs at the beginning with the first valid Supertrend value\n",
    "      first_valid_st_idx = np.where(~np.isnan(supertrend))[0][0] if np.any(~np.isnan(supertrend)) else len(close)\n",
    "      if first_valid_st_idx < len(close):\n",
    "          supertrend[:first_valid_st_idx] = supertrend[first_valid_st_idx]\n",
    " \n",
    " \n",
    "      return supertrend, direction\n",
    " \n",
    "  def calculate_start_date(interval):\n",
    "      \"\"\"Calcola la data di inizio per il download dei dati in base all'intervallo.\"\"\"\n",
    "      today = datetime.now()\n",
    "      if interval == \"1d\":\n",
    "          # 6 mesi per il daily\n",
    "          return today - relativedelta(months=6)\n",
    "      elif interval == \"1wk\":\n",
    "          # 1 anno per il weekly\n",
    "          return today - relativedelta(years=1)\n",
    "      elif interval == \"1mo\":\n",
    "          # 2 anni per il monthly\n",
    "          return today - relativedelta(years=2)\n",
    "      elif interval == \"4h\":\n",
    "          # 60 giorni per il 4h\n",
    "          return today - timedelta(days=60)\n",
    "      else:\n",
    "          return None # O gestisci altri intervalli se necessario\n",
    " \n",
    "  def fix_df(df):\n",
    "      \"\"\"Rimuove MultiIndex e converte colonne in float\"\"\"\n",
    "      if isinstance(df.columns, pd.MultiIndex):\n",
    "          df.columns = [col[0] for col in df.columns]\n",
    "      for col in ['Open','High','Low','Close','Adj Close','Volume']:\n",
    "          if col in df.columns:\n",
    "              # Use errors='coerce' to turn problematic values into NaN\n",
    "              df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "              # Drop rows with NaN in critical columns if necessary, or handle NaNs later\n",
    "              # df.dropna(subset=[col], inplace=True) # Uncomment if dropping rows with NaN is desired\n",
    " \n",
    "      # Ensure index is datetime\n",
    "      if not isinstance(df.index, pd.DatetimeIndex):\n",
    "          df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "          df.dropna(inplace=True) # Drop rows where index couldn't be converted\n",
    " \n",
    "      return df\n",
    " \n",
    " \n",
    "  # === 3. Funzione che calcola ST per 4H/Daily/Weekly/Monthly ===\n",
    "  def get_supertrend_signals(ticker, atr_period=10, multiplier=3.0):\n",
    "      try:\n",
    "          # Suppress output when downloading data\n",
    "          with open(os.devnull, 'w') as f:\n",
    "            with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "              start_date_daily = calculate_start_date(\"1d\")\n",
    "              start_date_weekly = calculate_start_date(\"1wk\")\n",
    "              start_date_monthly = calculate_start_date(\"1mo\")\n",
    "              start_date_4h = calculate_start_date(\"4h\")\n",
    " \n",
    "              # Added check for start_date being None\n",
    "              df_daily = fix_df(yf.download(ticker, start=start_date_daily, interval=\"1d\", auto_adjust=True) if start_date_daily else pd.DataFrame())\n",
    "              df_weekly = fix_df(yf.download(ticker, start=start_date_weekly, interval=\"1wk\", auto_adjust=True) if start_date_weekly else pd.DataFrame())\n",
    "              df_monthly = fix_df(yf.download(ticker, start=start_date_monthly, interval=\"1mo\", auto_adjust=True) if start_date_monthly else pd.DataFrame())\n",
    "              df_4h = fix_df(yf.download(ticker, start=start_date_4h, interval=\"4h\", auto_adjust=True) if start_date_4h else pd.DataFrame())\n",
    " \n",
    " \n",
    "          # Added checks for required columns after fixing df\n",
    "          if df_daily.empty or 'Close' not in df_daily.columns or 'High' not in df_daily.columns or 'Low' not in df_daily.columns:\n",
    "              print(f\"Dati giornalieri insufficienti o incompleti per {ticker}\")\n",
    "              st_daily_signal = \"Err\"\n",
    "              close_price = np.nan # Use NaN if daily data is missing\n",
    "          else:\n",
    "              st_daily, dir_daily = calculate_supertrend(df_daily['High'], df_daily['Low'], df_daily['Close'], atr_period, multiplier)\n",
    "              # Check if the last Supertrend value is not NaN before checking the signal\n",
    "              st_daily_last = st_daily[-1] if not np.isnan(st_daily[-1]) else np.nan\n",
    "              close_price = df_daily['Close'].iloc[-1]\n",
    "              st_daily_signal = \"V\" if not np.isnan(st_daily_last) and close_price > st_daily_last else \"R\" if not np.isnan(st_daily_last) else \"Err\"\n",
    " \n",
    " \n",
    "          if df_weekly.empty or 'Close' not in df_weekly.columns or 'High' not in df_weekly.columns or 'Low' not in df_weekly.columns:\n",
    "              print(f\"Dati settimanali insufficienti o incompleti per {ticker}\")\n",
    "              st_weekly_signal = \"Err\"\n",
    "          else:\n",
    "              st_weekly, dir_weekly = calculate_supertrend(df_weekly['High'], df_weekly['Low'], df_weekly['Close'], atr_period, multiplier)\n",
    "              st_weekly_last = st_weekly[-1] if not np.isnan(st_weekly[-1]) else np.nan\n",
    "              st_weekly_signal = \"V\" if not np.isnan(st_weekly_last) and close_price > st_weekly_last else \"R\" if not np.isnan(st_weekly_last) else \"Err\"\n",
    " \n",
    " \n",
    "          if df_monthly.empty or 'Close' not in df_monthly.columns or 'High' not in df_monthly.columns or 'Low' not in df_monthly.columns:\n",
    "              print(f\"Dati mensili insufficienti o incompleti per {ticker}\")\n",
    "              st_monthly_signal = \"Err\"\n",
    "          else:\n",
    "              st_monthly, dir_monthly = calculate_supertrend(df_monthly['High'], df_monthly['Low'], df_monthly['Close'], atr_period, multiplier)\n",
    "              st_monthly_last = st_monthly[-1] if not np.isnan(st_monthly[-1]) else np.nan\n",
    "              st_monthly_signal = \"V\" if not np.isnan(st_monthly_last) and close_price > st_monthly_last else \"R\" if not np.isnan(st_monthly_last) else \"Err\"\n",
    " \n",
    " \n",
    "          if df_4h.empty or 'Close' not in df_4h.columns or 'High' not in df_4h.columns or 'Low' not in df_4h.columns:\n",
    "              print(f\"Dati 4h insufficienti o incompleti per {ticker}\")\n",
    "              st_4h_signal = \"Err\"\n",
    "          else:\n",
    "              st_4h, dir_4h = calculate_supertrend(df_4h['High'], df_4h['Low'], df_4h['Close'], atr_period, multiplier)\n",
    "              st_4h_last = st_4h[-1] if not np.isnan(st_4h[-1]) else np.nan\n",
    "              st_4h_signal = \"V\" if not np.isnan(st_4h_last) and close_price > st_4h_last else \"R\" if not np.isnan(st_4h_last) else \"Err\"\n",
    " \n",
    " \n",
    "          return st_4h_signal, st_daily_signal, st_weekly_signal, st_monthly_signal\n",
    " \n",
    "      except Exception as e:\n",
    "          print(f\"Errore durante il calcolo del SuperTrend per {ticker}: {e}\")\n",
    "          return \"Err\",\"Err\",\"Err\",\"Err\"\n",
    " \n",
    "  # === 4. Applica ai ticker del file POC ===\n",
    "  df_poc[['ST_4H','ST_Daily','ST_Weekly','ST_Monthly']] = df_poc['Ticker'].apply(\n",
    "      lambda x: pd.Series(get_supertrend_signals(x))\n",
    "  )\n",
    " \n",
    "  print(\"\\nTabella finale con segnali SuperTrend:\")\n",
    "  # Controlla se ci sono colonne SuperTrend prima di stampare\n",
    "  supertrend_cols = ['ST_4H','ST_Daily','ST_Weekly','ST_Monthly']\n",
    "  if any(col in df_poc.columns for col in supertrend_cols):\n",
    "      print(df_poc.round(1).to_string())\n",
    "  else:\n",
    "      print(\"Nessun dato SuperTrend calcolato.\")\n",
    " \n",
    " \n",
    "  # === 5. Esporta in Excel ===\n",
    "  output_dir = '/content/drive/MyDrive/Supertrend'\n",
    "  os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    " \n",
    "  output_file_path = os.path.join(output_dir, f'SuperTrend_POC{poc_period}_week_{week_number}.xlsx')\n",
    "  df_poc.to_excel(output_file_path, index=False)\n",
    " \n",
    "  print(f\"\\nTabella esportata in: {output_file_path}\")\n",
    " \n",
    "else:\n",
    "  print(\"Skipping SuperTrend calculation as POC file was not loaded.\")\n",
    "  # Puoi aggiungere qui un'alternativa o semplicemente terminare lo script in modo pulito\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
