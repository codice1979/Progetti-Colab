{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92148ca2-077e-46e6-9950-2f7e88a17d77",
   "metadata": {},
   "outputs": [],
   "source": [
    " ======================================================\n",
    "# üì¶ Scarica i ticker di S&P 500 e Nasdaq 100 da Wikipedia\n",
    "# ======================================================\n",
    " \n",
    "!pip install yfinance openpyxl pandas requests matplotlib beautifulsoup4 lxml --quiet\n",
    " \n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from io import StringIO\n",
    " \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    " \n",
    "print(\"üì• Scaricamento ticker S&P 500 e Nasdaq 100 da Wikipedia...\")\n",
    " \n",
    "tickers = set()\n",
    " \n",
    "# Funzione helper per leggere una tabella da Wikipedia con header browser-like\n",
    "def read_html_with_headers(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return pd.read_html(StringIO(response.text))\n",
    " \n",
    "# ======================================================\n",
    "# üßæ S&P 500\n",
    "# ======================================================\n",
    "try:\n",
    "    url_sp500 = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    tables = read_html_with_headers(url_sp500)\n",
    "    df_sp500 = tables[0]  # La prima tabella √® quella giusta\n",
    "    sp500_tickers = df_sp500[\"Symbol\"].str.replace(\".\", \"-\", regex=False).tolist()\n",
    "    tickers.update(sp500_tickers)\n",
    "    print(f\"‚úÖ Ticker S&P 500 scaricati: {len(sp500_tickers)}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Errore caricamento S&P 500:\", e)\n",
    " \n",
    "# ======================================================\n",
    "# üßæ Nasdaq 100\n",
    "# ======================================================\n",
    "try:\n",
    "    url_nasdaq100 = \"https://en.wikipedia.org/wiki/NASDAQ-100\"\n",
    "    tables = read_html_with_headers(url_nasdaq100)\n",
    "    # Cerca la tabella corretta\n",
    "    df_nasdaq = next(df for df in tables if any(col in df.columns for col in [\"Ticker\", \"Symbol\"]))\n",
    "    ticker_col = \"Ticker\" if \"Ticker\" in df_nasdaq.columns else \"Symbol\"\n",
    "    nasdaq_tickers = df_nasdaq[ticker_col].str.replace(\".\", \"-\", regex=False).tolist()\n",
    "    tickers.update(nasdaq_tickers)\n",
    "    print(f\"‚úÖ Ticker Nasdaq 100 scaricati: {len(nasdaq_tickers)}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Errore caricamento Nasdaq 100:\", e)\n",
    " \n",
    "# ======================================================\n",
    "# üìä Risultati combinati\n",
    "# ======================================================\n",
    "all_tickers = sorted(tickers)\n",
    " \n",
    "print(f\"\\nüìà Totale ticker unici raccolti: {len(all_tickers)}\")\n",
    "print(\"Esempio dei primi 20 ticker:\", all_tickers[:20])\n",
    " \n",
    "# Salva in variabile per la cella successiva\n",
    "cleaned_combined_tickers = all_tickers\n",
    " \n",
    "# ======================================================\n",
    "# ‚ÑπÔ∏è Nota:\n",
    "# La variabile `cleaned_combined_tickers` contiene tutti i ticker unificati\n",
    "# Potrai ora usarla nella prossima cella per l‚Äôanalisi (es. % sopra SMA200)\n",
    "# ======================================================\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c91ec-6878-4635-bdeb-dc8985380d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================\n",
    "# üì¶ Scarica dati e calcola indicatore (% sopra MA200)\n",
    "# ======================================================\n",
    " \n",
    "# Assicurati che cleaned_combined_tickers sia disponibile dalla prima cella\n",
    "if 'cleaned_combined_tickers' not in locals():\n",
    "    raise RuntimeError(\"Variabile 'cleaned_combined_tickers' non trovata. Esegui prima la prima cella.\")\n",
    " \n",
    "start = '2010-01-01'        # Data di inizio per il download dei dati\n",
    " \n",
    "# Definisci gli indici da analizzare e i loro ticker corrispondenti\n",
    "indices_to_analyze = {\n",
    "    \"S&P 500\": \"SPY\",  # SPY √® un ETF che replica l'S&P 500\n",
    "    \"Nasdaq 100\": \"QQQ\" # QQQ √® un ETF che replica il Nasdaq 100\n",
    "}\n",
    " \n",
    "# Dictionaries to store data and indicators for each index\n",
    "data_dict = {}\n",
    "index_dict = {}\n",
    "above200_dict = {}\n",
    "valid_tickers_dict = {}\n",
    " \n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üì• Scaricamento dati e calcolo indicatore per Indici\")\n",
    "print(f\"{'='*50}\")\n",
    " \n",
    "for index_name, index_ticker in indices_to_analyze.items():\n",
    "    print(f\"\\nElaborazione per {index_name} ({index_ticker})...\")\n",
    " \n",
    "    # Use all cleaned_combined_tickers for analysis\n",
    "    tickers = cleaned_combined_tickers\n",
    " \n",
    "    if not tickers:\n",
    "        print(f\"‚ùå Nessun ticker trovato per {index_name}.\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    # DOWNLOAD DATI\n",
    "    try:\n",
    "        # Download data for all tickers at once\n",
    "        data = yf.download(tickers, start=start, period=\"max\", interval=\"1d\", progress=False, auto_adjust=False)['Adj Close']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il download dei dati dei ticker per {index_name}: {e}\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    if data.empty:\n",
    "        print(f\"‚ùå Nessun dato valido scaricato per i ticker di {index_name}.\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    # Download index data\n",
    "    try:\n",
    "        index = yf.download(index_ticker, start=start, period=\"max\", interval=\"1d\", progress=False, auto_adjust=False)['Adj Close']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il download dei dati dell'indice {index_ticker}: {e}\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    if index.empty:\n",
    "        print(f\"‚ùå Nessun dato valido scaricato per l'indice {index_ticker}.\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    # Align data and index\n",
    "    data, index = data.align(index, join='inner', axis=0)\n",
    " \n",
    "    # Filter out tickers that have become all NaNs after alignment\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    valid_tickers = data.columns.tolist()\n",
    " \n",
    "    if not valid_tickers:\n",
    "        print(f\"‚ùå Nessun ticker valido rimasto dopo l'allineamento dei dati per {index_name}.\")\n",
    "        continue # Skip to the next index\n",
    " \n",
    "    print(f\"\\n‚úÖ Dati scaricati per {len(valid_tickers)} tickers validi per {index_name}.\")\n",
    " \n",
    "    # ==========================================\n",
    "    # CALCOLO INDICATORE (% sopra MA200)\n",
    "    # ==========================================\n",
    "    ma200 = data.rolling(200).mean()\n",
    "    # Use the length of valid_tickers AFTER alignment for the calculation\n",
    "    above200 = (data > ma200).sum(axis=1) / len(valid_tickers) * 100\n",
    " \n",
    "    # Store data and indicator in dictionaries\n",
    "    data_dict[index_name] = data\n",
    "    index_dict[index_name] = index\n",
    "    above200_dict[index_name] = above200\n",
    "    valid_tickers_dict[index_name] = valid_tickers\n",
    " \n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"‚úÖ Scaricamento dati e calcolo indicatore completati.\")\n",
    "print(\"Le variabili 'data_dict', 'index_dict', 'above200_dict', 'valid_tickers_dict' contengono i dati per ciascun indice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f5176-ae44-47c7-9b2a-6d5d0a709207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Import seaborn for heatmap\n",
    " \n",
    "# ==========================================\n",
    "# PARAMETRI MODIFICABILI (per backtest variabile)\n",
    "# ==========================================\n",
    " \n",
    "# Inserisci qui i parametri che vuoi testare manualmente\n",
    "fixed_parameters = {\n",
    "    \"S&P 500\": {\"buy_threshold\": 21, \"holding_days\": 110},  # Esempio: puoi cambiare questi valori\n",
    "    \"Nasdaq 100\": {\"buy_threshold\": 31, \"holding_days\": 70} # Esempio: puoi cambiare questi valori\n",
    "}\n",
    " \n",
    "# ==========================================\n",
    "# ANALISI PER OGNI INDICE (S&P 500 e Nasdaq 100)\n",
    "# ==========================================\n",
    " \n",
    "# Assicurati che i dati siano disponibili dalla cella precedente (Scarica dati)\n",
    "if 'above200_dict' not in locals() or 'index_dict' not in locals():\n",
    "    raise RuntimeError(\"Variabili necessarie ('above200_dict' o 'index_dict') non trovate. Esegui prima la cella 'Scarica dati'.\")\n",
    " \n",
    "# Definisci gli indici da analizzare (basandosi sulle chiavi dei dictionary di dati)\n",
    "indices_to_analyze = above200_dict.keys()\n",
    " \n",
    "# Loop through each index\n",
    "for index_name in indices_to_analyze:\n",
    " \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üöÄ Analisi Backtesting con Parametri Variabili per {index_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    " \n",
    "    # Get the fixed parameters for the current index\n",
    "    if index_name not in fixed_parameters:\n",
    "        print(f\"‚ùå Parametri fissi non definiti per {index_name}. Salto l'analisi.\")\n",
    "        continue\n",
    " \n",
    "    buy_threshold = fixed_parameters[index_name][\"buy_threshold\"]\n",
    "    holding_days = fixed_parameters[index_name][\"holding_days\"]\n",
    " \n",
    "    print(f\"Utilizzo parametri: Soglia BUY={buy_threshold}%, Holding Days={holding_days} giorni\")\n",
    " \n",
    "    # Get data for the current index from the dictionaries\n",
    "    above200 = above200_dict[index_name]\n",
    "    index = index_dict[index_name]\n",
    " \n",
    "    # ==========================================\n",
    "    # FUNZIONE DI BACKTEST (uscita dopo X giorni - entrata su cross)\n",
    "    # ==========================================\n",
    "    # Ensure the function is defined here or accessible globally if defined elsewhere\n",
    "    def backtest_timed_exit(above200, index, buy_thr, hold_days):\n",
    "        position = 0\n",
    "        days_in_trade = 0\n",
    "        signal = pd.Series(0, index=above200.index)\n",
    " \n",
    "        for i in range(1, len(signal)):\n",
    "            # Check if the current date and previous date exist in above200 and index\n",
    "            if (signal.index[i] in above200.index and signal.index[i] in index.index and\n",
    "                signal.index[i-1] in above200.index and signal.index[i-1] in index.index): # Ensure previous day also exists in index and above200\n",
    " \n",
    "                # Entry condition: only if flat AND indicator crosses below buy_thr\n",
    "                if position == 0 and above200.iloc[i] < buy_thr and above200.iloc[i-1] >= buy_thr:\n",
    "                    position = 1\n",
    "                    days_in_trade = 0 # Reset days_in_trade on new entry\n",
    " \n",
    "                elif position == 1:\n",
    "                    days_in_trade += 1\n",
    "                    if days_in_trade >= hold_days:\n",
    "                        position = 0 # Exit after hold_days\n",
    " \n",
    "                signal.iloc[i] = position\n",
    " \n",
    "        returns = index.pct_change().fillna(0)\n",
    "        # Ensure signal is aligned to the returns index before multiplication\n",
    "        aligned_signal = signal.reindex(returns.index).fillna(0)\n",
    "        # Calculate strategy returns by multiplying index returns with the aligned signal\n",
    "        # Ensure returns is a Series before multiplication if it was a DataFrame\n",
    "        if isinstance(returns, pd.DataFrame):\n",
    "            strategy_returns = returns.iloc[:, 0] * aligned_signal\n",
    "        else: # It's already a Series\n",
    "            strategy_returns = returns * aligned_signal\n",
    " \n",
    "        # Ensure strategy is a Series before cumsum\n",
    "        strategy = strategy_returns.cumsum()\n",
    " \n",
    "        total_return = np.exp(strategy.iloc[-1]) - 1\n",
    "        cagr = (1 + total_return) ** (252 / len(index)) - 1 # Using len(index) for days in CAGR calculation\n",
    " \n",
    "        return cagr, strategy, signal\n",
    " \n",
    "    # ==========================================\n",
    "    # ESECUZIONE BACKTEST CON PARAMETRI VARIABILI\n",
    "    # ==========================================\n",
    "    print(f\"\\nüî¨ Esecuzione backtest con parametri variabili per {index_name}...\")\n",
    " \n",
    "    try:\n",
    "        cagr, strat, signal = backtest_timed_exit(above200, index, buy_threshold, holding_days)\n",
    " \n",
    "        print(f\"\\n‚úÖ Backtest completato per {index_name}:\")\n",
    "        print(f\"   Parametri utilizzati: Soglia BUY={buy_threshold}%, Holding Days={holding_days} giorni\")\n",
    "        print(f\"   CAGR: {cagr:.4f}\")\n",
    " \n",
    "        # ==========================================\n",
    "        # GRAFICO EQUITY LINE\n",
    "        # ==========================================\n",
    "        plt.figure(figsize=(12, 6)) # Increased figure size slightly\n",
    "        # Ensure plotting data is aligned\n",
    "        aligned_strat = np.exp(strat).reindex(index.index).ffill() # Use .ffill()\n",
    "        aligned_index = (index / index.iloc[0]).reindex(index.index).ffill() # Use .ffill()\n",
    " \n",
    "        plt.plot(aligned_strat, label=f'Strategy (Buy<{buy_threshold}%, hold {holding_days}d, cross)')\n",
    "        plt.plot(aligned_index, label='Buy & Hold', alpha=0.5)\n",
    "        plt.title(f\"Equity line strategia breadth su {index_name} (holding {holding_days} giorno/i, entrata su cross)\")\n",
    "        plt.xlabel(\"Date\") # Added X-axis label\n",
    "        plt.ylabel(\"Cumulative Return (Factor)\") # Added Y-axis label\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45) # Rotate x-axis labels\n",
    "        plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "        plt.show()\n",
    " \n",
    "        # ==========================================\n",
    "        # GRAFICO DELL‚ÄôINDICATORE + SEGNALI\n",
    "        # ==========================================\n",
    "        plt.figure(figsize=(12, 6)) # Increased figure size slightly\n",
    "        plt.plot(above200, label='% sopra MA200')\n",
    "        plt.axhline(buy_threshold, color='red', linestyle='--', label=f'Soglia Buy {buy_threshold}%')\n",
    "        # Ensure signal is aligned for plotting\n",
    "        aligned_signal = signal.reindex(above200.index).fillna(0)\n",
    "        plt.fill_between(above200.index, 0, 100, where=aligned_signal > 0, color='green', alpha=0.1, label='Posizione Long')\n",
    "        plt.title(f\"Indicatore breadth con segnali di acquisto su {index_name} (holding {holding_days} giorno/i, entrata su cross)\")\n",
    "        plt.xlabel(\"Date\") # Added X-axis label\n",
    "        plt.ylabel(\"% Above MA200\") # Added Y-axis label\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45) # Rotate x-axis labels\n",
    "        plt.tight_layout() # Adjust layout\n",
    "        plt.show()\n",
    " \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il backtest con parametri variabili per {index_name}: {e}\")\n",
    " \n",
    "# ==========================================\n",
    "# RIEPILOGO FINALE BACKTEST VARIABILE\n",
    "# ==========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üìä Riepilogo Backtest con Parametri Variabili\")\n",
    "print(f\"{'='*50}\")\n",
    " \n",
    "# Note: The results for the fixed backtest are printed directly above for each index.\n",
    "print(\"Consulta l'output sopra per i risultati dettagliati del backtest con parametri variabili per ciascun indice.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad04e5-ace1-4413-ae37-3439af6bde11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Import seaborn for heatmap\n",
    " \n",
    "# ==========================================\n",
    "# OTTIMIZZAZIONE PARAMETRI (Soglia BUY e Holding Days)\n",
    "# ==========================================\n",
    " \n",
    "# Assicurati che i dati siano disponibili dalla cella precedente (Scarica dati)\n",
    "if 'above200_dict' not in locals() or 'index_dict' not in locals():\n",
    "    raise RuntimeError(\"Variabili necessarie ('above200_dict' o 'index_dict') non trovate. Esegui prima la cella 'Scarica dati'.\")\n",
    " \n",
    "buy_threshold_range = range(5, 55, 2) # Range e passo per testare le soglie BUY\n",
    "holding_days_range = range(20, 120, 10) # Range e passo per testare i giorni di holding\n",
    " \n",
    "optimization_results = {} # Dictionary to store optimization results for heatmap\n",
    "best_results_optimization = {} # Dictionary to store best results from optimization\n",
    " \n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üî¨ Esecuzione Ottimizzazione Parametri (Soglia BUY vs Holding Days)\")\n",
    "print(f\"{'='*50}\")\n",
    " \n",
    "# Definisci gli indici da analizzare (basandosi sulle chiavi dei dictionary di dati)\n",
    "indices_to_analyze = above200_dict.keys()\n",
    " \n",
    "for index_name in indices_to_analyze:\n",
    "    print(f\"\\nOttimizzazione per {index_name}...\")\n",
    " \n",
    "    # Get data for the current index from the dictionaries\n",
    "    above200_opt = above200_dict[index_name]\n",
    "    index_opt = index_dict[index_name]\n",
    " \n",
    "    results_grid = pd.DataFrame(index=list(buy_threshold_range), columns=list(holding_days_range))\n",
    " \n",
    "    for buy in buy_threshold_range:\n",
    "        for hold in holding_days_range:\n",
    "            try:\n",
    "                # Use data specific to this optimization process\n",
    "                # Ensure backtest_timed_exit function is accessible (defined in variable backtest cell or globally)\n",
    "                cagr, _, _ = backtest_timed_exit(above200_opt, index_opt, buy, hold)\n",
    "                results_grid.loc[buy, hold] = cagr\n",
    "            except Exception as e:\n",
    "                # print(f\"‚ö† Errore durante il backtest per {index_name} con soglia BUY={buy}% e holding={hold}d: {e}\")\n",
    "                results_grid.loc[buy, hold] = np.nan # Append NaN for failed backtest\n",
    " \n",
    "    # Convert results_grid to numeric, coercing errors to NaN\n",
    "    results_grid = results_grid.apply(pd.to_numeric, errors='coerce')\n",
    "    optimization_results[index_name] = results_grid # Store results grid\n",
    " \n",
    "    # Find the best combination\n",
    "    if not results_grid.dropna().empty:\n",
    "        best_cagr = results_grid.max().max()\n",
    "        best_buy = results_grid.stack().idxmax()[0]\n",
    "        best_hold = results_grid.stack().idxmax()[1]\n",
    " \n",
    "        best_results_optimization[index_name] = {'Buy': best_buy, 'Holding Days': best_hold, 'CAGR': best_cagr}\n",
    " \n",
    "        print(f\"\\n‚≠ê Miglior combinazione trovata per {index_name} nell'ottimizzazione:\")\n",
    "        print(f\"   Soglia BUY: {best_buy}%\")\n",
    "        print(f\"   Holding Days: {best_hold} giorni\")\n",
    "        print(f\"   CAGR: {best_cagr:.4f}\")\n",
    " \n",
    "        # ==========================================\n",
    "        # GRAFICO HEATMAP DEI RISULTATI\n",
    "        # ==========================================\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(results_grid, annot=True, fmt=\".4f\", cmap=\"viridis\", cbar_kws={'label': 'CAGR'})\n",
    "        plt.title(f\"Heatmap Ottimizzazione Parametri per {index_name} (Soglia BUY vs Holding Days)\")\n",
    "        plt.xlabel(\"Holding Days\")\n",
    "        plt.ylabel(\"Soglia BUY (%)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    " \n",
    "    else:\n",
    "         print(f\"\\n‚ùå Nessun risultato di backtest valido trovato per {index_name} per l'ottimizzazione bidimensionale.\")\n",
    " \n",
    "# ==========================================\n",
    "# RIEPILOGO FINALE OTTIMIZZAZIONE\n",
    "# ==========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üìä Riepilogo Migliori Combinazioni di Parametri dall'Ottimizzazione\")\n",
    "print(f\"{'='*50}\")\n",
    " \n",
    "if best_results_optimization:\n",
    "    df_summary_opt = pd.DataFrame.from_dict(best_results_optimization, orient='index')\n",
    "    df_summary_opt.index.name = 'Indice'\n",
    "    df_summary_opt = df_summary_opt[['Buy', 'Holding Days', 'CAGR']]\n",
    "    df_summary_opt.rename(columns={'Buy': 'Miglior Soglia BUY (%)'}, inplace=True)\n",
    "    df_summary_opt['Miglior Soglia BUY (%)'] = df_summary_opt['Miglior Soglia BUY (%)'].astype(int)\n",
    "    df_summary_opt['Holding Days'] = df_summary_opt['Holding Days'].astype(int)\n",
    "    print(df_summary_opt.to_string(formatters={'CAGR': '{:.4f}'.format}))\n",
    "else:\n",
    "    print(\"‚ùå Nessun risultato valido dall'ottimizzazione da riepilogare.\")\n",
    " \n",
    "# Note: The best_results_optimization dictionary contains the results you can use\n",
    "# to set the parameters in the main backtesting cell (cell 2).\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
